{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "protected-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scispacy\n",
    "import spacy\n",
    "import ndjson\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-contribution",
   "metadata": {},
   "source": [
    "Make a genia 2 and take only the head of train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "weighted-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = Path(os.getcwd())\n",
    "root_dir = pwd.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hired-wireless",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "instant-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data/genia2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "nearby-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r data/genia/normalized-data/json-coref-all/* data/genia2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-cannon",
   "metadata": {},
   "source": [
    "How big is train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "divine-biology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1568 data/genia2/train.json\n"
     ]
    }
   ],
   "source": [
    "!wc -l data/genia2/train.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-melbourne",
   "metadata": {},
   "source": [
    "Its important to replace the dataset argument for all records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "intended-printer",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find . -name '/data/genia2/*.json' -exec sed -i.bak -e 's/\"dataset\": \"genia\"/\"dataset\": \"genia2\"/g' {} \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-temperature",
   "metadata": {},
   "source": [
    "Lets make smaller versions of all datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "mental-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 100 data/genia2/train.json > data/genia2/train_sample.json\n",
    "!head -n 100 data/genia2/dev.json > data/genia2/dev_sample.json\n",
    "!head -n 100 data/genia2/test.json > data/genia2/test_sample.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-underground",
   "metadata": {},
   "source": [
    "We need to make the config based on the genia config.\n",
    "I copied the genia config and replaced the data with the samples, then I reduced the epochs to 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-market",
   "metadata": {},
   "source": [
    "Then, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "paperback-lodging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-31 18:33:05,289 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2021-01-31 18:33:05,355 - INFO - allennlp.common.params - include_in_archive = None\n",
      "2021-01-31 18:33:05,356 - INFO - allennlp.common.params - random_seed = 13370\n",
      "2021-01-31 18:33:05,356 - INFO - allennlp.common.params - numpy_seed = 1337\n",
      "2021-01-31 18:33:05,356 - INFO - allennlp.common.params - pytorch_seed = 133\n",
      "2021-01-31 18:33:05,435 - INFO - allennlp.common.checks - Pytorch version: 1.7.1\n",
      "2021-01-31 18:33:05,435 - INFO - allennlp.common.params - type = default\n",
      "2021-01-31 18:33:05,436 - INFO - allennlp.common.params - dataset_reader.type = dygie\n",
      "2021-01-31 18:33:05,436 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
      "2021-01-31 18:33:05,437 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
      "2021-01-31 18:33:05,437 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2021-01-31 18:33:05,437 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2021-01-31 18:33:05,437 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
      "2021-01-31 18:33:05,437 - INFO - allennlp.common.params - dataset_reader.max_span_width = 8\n",
      "2021-01-31 18:33:05,437 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = pretrained_transformer_mismatched\n",
      "2021-01-31 18:33:05,438 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.token_min_padding_length = 0\n",
      "2021-01-31 18:33:05,438 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.model_name = microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\n",
      "2021-01-31 18:33:05,438 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.namespace = tags\n",
      "2021-01-31 18:33:05,438 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_length = 512\n",
      "2021-01-31 18:33:05,438 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.tokenizer_kwargs = None\n",
      "2021-01-31 18:33:17,593 - INFO - allennlp.common.params - train_data_path = data/genia2/train_sample.json\n",
      "2021-01-31 18:33:17,594 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f50f4165a90>\n",
      "2021-01-31 18:33:17,594 - INFO - allennlp.common.params - datasets_for_vocab_creation = None\n",
      "2021-01-31 18:33:17,594 - INFO - allennlp.common.params - validation_dataset_reader = None\n",
      "2021-01-31 18:33:17,594 - INFO - allennlp.common.params - validation_data_path = data/genia2/dev_sample.json\n",
      "2021-01-31 18:33:17,595 - INFO - allennlp.common.params - validation_data_loader = None\n",
      "2021-01-31 18:33:17,595 - INFO - allennlp.common.params - test_data_path = data/genia2/test_sample.json\n",
      "2021-01-31 18:33:17,595 - INFO - allennlp.common.params - evaluate_on_test = False\n",
      "2021-01-31 18:33:17,595 - INFO - allennlp.common.params - batch_weight_key = \n",
      "2021-01-31 18:33:17,595 - INFO - allennlp.training.util - Reading training data from data/genia2/train_sample.json\n",
      "reading instances: 100it [00:01, 70.58it/s]\n",
      "2021-01-31 18:33:19,012 - INFO - allennlp.training.util - Reading validation data from data/genia2/dev_sample.json\n",
      "reading instances: 100it [00:01, 70.77it/s]\n",
      "2021-01-31 18:33:20,426 - INFO - allennlp.training.util - Reading test data from data/genia2/test_sample.json\n",
      "reading instances: 100it [00:01, 86.05it/s]\n",
      "2021-01-31 18:33:21,588 - INFO - allennlp.common.params - type = from_instances\n",
      "2021-01-31 18:33:21,589 - INFO - allennlp.common.params - min_count = None\n",
      "2021-01-31 18:33:21,589 - INFO - allennlp.common.params - max_vocab_size = None\n",
      "2021-01-31 18:33:21,589 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')\n",
      "2021-01-31 18:33:21,589 - INFO - allennlp.common.params - pretrained_files = None\n",
      "2021-01-31 18:33:21,589 - INFO - allennlp.common.params - only_include_pretrained_words = False\n",
      "2021-01-31 18:33:21,589 - INFO - allennlp.common.params - tokens_to_add = None\n",
      "2021-01-31 18:33:21,589 - INFO - allennlp.common.params - min_pretrained_embeddings = None\n",
      "2021-01-31 18:33:21,589 - INFO - allennlp.common.params - padding_token = @@PADDING@@\n",
      "2021-01-31 18:33:21,590 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@\n",
      "2021-01-31 18:33:21,590 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n",
      "building vocab: 300it [00:00, 1216.39it/s]\n",
      "2021-01-31 18:33:21,837 - INFO - allennlp.common.params - model.type = dygie\n",
      "2021-01-31 18:33:21,837 - INFO - allennlp.common.params - model.embedder.type = basic\n",
      "2021-01-31 18:33:21,838 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.type = pretrained_transformer_mismatched\n",
      "2021-01-31 18:33:21,838 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.model_name = microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\n",
      "2021-01-31 18:33:21,838 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.max_length = 512\n",
      "2021-01-31 18:33:21,838 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.train_parameters = True\n",
      "2021-01-31 18:33:21,838 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.last_layer_only = True\n",
      "2021-01-31 18:33:21,838 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.gradient_checkpointing = None\n",
      "2021-01-31 18:33:21,838 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.tokenizer_kwargs = None\n",
      "2021-01-31 18:33:21,838 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.transformer_kwargs = None\n",
      "2021-01-31 18:33:26,976 - INFO - allennlp.common.params - model.modules.coref.coref_prop = 2\n",
      "2021-01-31 18:33:26,976 - INFO - allennlp.common.params - model.modules.coref.max_antecedents = 100\n",
      "2021-01-31 18:33:26,976 - INFO - allennlp.common.params - model.modules.coref.spans_per_word = 0.3\n",
      "2021-01-31 18:33:26,976 - INFO - allennlp.common.params - model.modules.events.argument_spans_per_word = 0.8\n",
      "2021-01-31 18:33:26,976 - INFO - allennlp.common.params - model.modules.events.loss_weights.arguments = 1\n",
      "2021-01-31 18:33:26,976 - INFO - allennlp.common.params - model.modules.events.loss_weights.trigger = 0.2\n",
      "2021-01-31 18:33:26,976 - INFO - allennlp.common.params - model.modules.events.trigger_spans_per_word = 0.3\n",
      "2021-01-31 18:33:26,976 - INFO - allennlp.common.params - model.modules.relation.spans_per_word = 0.5\n",
      "2021-01-31 18:33:26,976 - INFO - allennlp.common.params - model.feature_size = 20\n",
      "2021-01-31 18:33:26,976 - INFO - allennlp.common.params - model.max_span_width = 8\n",
      "2021-01-31 18:33:26,976 - INFO - allennlp.common.params - model.target_task = ner\n",
      "2021-01-31 18:33:26,977 - INFO - allennlp.common.params - model.initializer.regexes.0.1.type = xavier_normal\n",
      "2021-01-31 18:33:26,977 - INFO - allennlp.common.params - model.initializer.regexes.0.1.gain = 1.0\n",
      "2021-01-31 18:33:26,977 - INFO - allennlp.common.params - model.initializer.prevent_regexes = None\n",
      "2021-01-31 18:33:26,977 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.type = xavier_normal\n",
      "2021-01-31 18:33:26,978 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.gain = 1.0\n",
      "2021-01-31 18:33:26,978 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.type = xavier_normal\n",
      "2021-01-31 18:33:26,978 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.gain = 1.0\n",
      "2021-01-31 18:33:26,978 - INFO - allennlp.common.params - model.module_initializer.prevent_regexes = None\n",
      "2021-01-31 18:33:26,978 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2021-01-31 18:33:26,978 - INFO - allennlp.common.params - model.display_metrics = None\n",
      "2021-01-31 18:33:26,978 - INFO - allennlp.common.params - ner.regularizer = None\n",
      "2021-01-31 18:33:26,981 - INFO - allennlp.common.params - coref.spans_per_word = 0.3\n",
      "2021-01-31 18:33:26,981 - INFO - allennlp.common.params - coref.max_antecedents = 100\n",
      "2021-01-31 18:33:26,981 - INFO - allennlp.common.params - coref.coref_prop = 2\n",
      "2021-01-31 18:33:26,981 - INFO - allennlp.common.params - coref.coref_prop_dropout_f = 0.0\n",
      "2021-01-31 18:33:26,981 - INFO - allennlp.common.params - coref.regularizer = None\n",
      "2021-01-31 18:33:27,017 - INFO - allennlp.common.params - relation.spans_per_word = 0.5\n",
      "2021-01-31 18:33:27,017 - INFO - allennlp.common.params - relation.positive_label_weight = 1.0\n",
      "2021-01-31 18:33:27,017 - INFO - allennlp.common.params - relation.regularizer = None\n",
      "2021-01-31 18:33:27,018 - INFO - allennlp.common.params - events.trigger_spans_per_word = 0.3\n",
      "2021-01-31 18:33:27,018 - INFO - allennlp.common.params - events.argument_spans_per_word = 0.8\n",
      "2021-01-31 18:33:27,018 - INFO - allennlp.common.params - events.regularizer = None\n",
      "2021-01-31 18:33:27,018 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2021-01-31 18:33:27,018 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.genia2__ner_labels.0._module._linear_layers.0.weight using .*weight initializer\n",
      "2021-01-31 18:33:27,020 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.genia2__ner_labels.0._module._linear_layers.1.weight using .*weight initializer\n",
      "2021-01-31 18:33:27,021 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.genia2__ner_labels.1._module.weight using .*weight initializer\n",
      "2021-01-31 18:33:27,021 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
      "2021-01-31 18:33:27,021 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2021-01-31 18:33:27,021 - INFO - allennlp.nn.initializers -    _ner_scorers.genia2__ner_labels.0._module._linear_layers.0.bias\n",
      "2021-01-31 18:33:27,021 - INFO - allennlp.nn.initializers -    _ner_scorers.genia2__ner_labels.0._module._linear_layers.1.bias\n",
      "2021-01-31 18:33:27,021 - INFO - allennlp.nn.initializers -    _ner_scorers.genia2__ner_labels.1._module.bias\n",
      "2021-01-31 18:33:27,021 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2021-01-31 18:33:27,021 - INFO - allennlp.nn.initializers - Initializing _distance_embedding.weight using .*weight initializer\n",
      "2021-01-31 18:33:27,022 - INFO - allennlp.nn.initializers - Initializing _antecedent_feedforward._module._linear_layers.0.weight using .*weight initializer\n",
      "2021-01-31 18:33:27,029 - INFO - allennlp.nn.initializers - Initializing _antecedent_feedforward._module._linear_layers.1.weight using .*weight initializer\n",
      "2021-01-31 18:33:27,029 - INFO - allennlp.nn.initializers - Initializing _mention_pruner._scorer.0._module._linear_layers.0.weight using .*weight initializer\n",
      "2021-01-31 18:33:27,031 - INFO - allennlp.nn.initializers - Initializing _mention_pruner._scorer.0._module._linear_layers.1.weight using .*weight initializer\n",
      "2021-01-31 18:33:27,032 - INFO - allennlp.nn.initializers - Initializing _mention_pruner._scorer.1._module.weight using .*weight initializer\n",
      "2021-01-31 18:33:27,032 - INFO - allennlp.nn.initializers - Initializing _antecedent_scorer._module.weight using .*weight initializer\n",
      "2021-01-31 18:33:27,032 - INFO - allennlp.nn.initializers - Initializing _f_network._linear_layers.0.weight using .*weight initializer\n",
      "2021-01-31 18:33:27,076 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
      "2021-01-31 18:33:27,077 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2021-01-31 18:33:27,077 - INFO - allennlp.nn.initializers -    _antecedent_feedforward._module._linear_layers.0.bias\n",
      "2021-01-31 18:33:27,077 - INFO - allennlp.nn.initializers -    _antecedent_feedforward._module._linear_layers.1.bias\n",
      "2021-01-31 18:33:27,077 - INFO - allennlp.nn.initializers -    _antecedent_scorer._module.bias\n",
      "2021-01-31 18:33:27,077 - INFO - allennlp.nn.initializers -    _f_network._linear_layers.0.bias\n",
      "2021-01-31 18:33:27,077 - INFO - allennlp.nn.initializers -    _mention_pruner._scorer.0._module._linear_layers.0.bias\n",
      "2021-01-31 18:33:27,077 - INFO - allennlp.nn.initializers -    _mention_pruner._scorer.0._module._linear_layers.1.bias\n",
      "2021-01-31 18:33:27,077 - INFO - allennlp.nn.initializers -    _mention_pruner._scorer.1._module.bias\n",
      "2021-01-31 18:33:27,077 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2021-01-31 18:33:27,077 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
      "2021-01-31 18:33:27,077 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight\n",
      "2021-01-31 18:33:27,077 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2021-01-31 18:33:27,077 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2021-01-31 18:33:27,077 - INFO - allennlp.nn.initializers - Initializing _distance_embedding.weight using .*weight initializer\n",
      "2021-01-31 18:33:27,078 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
      "2021-01-31 18:33:27,078 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2021-01-31 18:33:27,078 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2021-01-31 18:33:27,078 - INFO - allennlp.nn.initializers - Initializing _endpoint_span_extractor._span_width_embedding.weight using _span_width_embedding.weight initializer\n",
      "2021-01-31 18:33:27,080 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2021-01-31 18:33:27,081 - INFO - allennlp.nn.initializers -    _coref._antecedent_feedforward._module._linear_layers.0.bias\n",
      "2021-01-31 18:33:27,081 - INFO - allennlp.nn.initializers -    _coref._antecedent_feedforward._module._linear_layers.0.weight\n",
      "2021-01-31 18:33:27,081 - INFO - allennlp.nn.initializers -    _coref._antecedent_feedforward._module._linear_layers.1.bias\n",
      "2021-01-31 18:33:27,081 - INFO - allennlp.nn.initializers -    _coref._antecedent_feedforward._module._linear_layers.1.weight\n",
      "2021-01-31 18:33:27,081 - INFO - allennlp.nn.initializers -    _coref._antecedent_scorer._module.bias\n",
      "2021-01-31 18:33:27,081 - INFO - allennlp.nn.initializers -    _coref._antecedent_scorer._module.weight\n",
      "2021-01-31 18:33:27,081 - INFO - allennlp.nn.initializers -    _coref._distance_embedding.weight\n",
      "2021-01-31 18:33:27,081 - INFO - allennlp.nn.initializers -    _coref._f_network._linear_layers.0.bias\n",
      "2021-01-31 18:33:27,081 - INFO - allennlp.nn.initializers -    _coref._f_network._linear_layers.0.weight\n",
      "2021-01-31 18:33:27,081 - INFO - allennlp.nn.initializers -    _coref._mention_pruner._scorer.0._module._linear_layers.0.bias\n",
      "2021-01-31 18:33:27,081 - INFO - allennlp.nn.initializers -    _coref._mention_pruner._scorer.0._module._linear_layers.0.weight\n",
      "2021-01-31 18:33:27,081 - INFO - allennlp.nn.initializers -    _coref._mention_pruner._scorer.0._module._linear_layers.1.bias\n",
      "2021-01-31 18:33:27,081 - INFO - allennlp.nn.initializers -    _coref._mention_pruner._scorer.0._module._linear_layers.1.weight\n",
      "2021-01-31 18:33:27,081 - INFO - allennlp.nn.initializers -    _coref._mention_pruner._scorer.1._module.bias\n",
      "2021-01-31 18:33:27,081 - INFO - allennlp.nn.initializers -    _coref._mention_pruner._scorer.1._module.weight\n",
      "2021-01-31 18:33:27,081 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
      "2021-01-31 18:33:27,081 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
      "2021-01-31 18:33:27,081 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
      "2021-01-31 18:33:27,081 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
      "2021-01-31 18:33:27,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
      "2021-01-31 18:33:27,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
      "2021-01-31 18:33:27,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
      "2021-01-31 18:33:27,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
      "2021-01-31 18:33:27,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
      "2021-01-31 18:33:27,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
      "2021-01-31 18:33:27,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
      "2021-01-31 18:33:27,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
      "2021-01-31 18:33:27,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
      "2021-01-31 18:33:27,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
      "2021-01-31 18:33:27,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
      "2021-01-31 18:33:27,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
      "2021-01-31 18:33:27,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
      "2021-01-31 18:33:27,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
      "2021-01-31 18:33:27,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
      "2021-01-31 18:33:27,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
      "2021-01-31 18:33:27,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
      "2021-01-31 18:33:27,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
      "2021-01-31 18:33:27,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
      "2021-01-31 18:33:27,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _events._distance_embedding.weight\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.genia2__ner_labels.0._module._linear_layers.0.bias\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.genia2__ner_labels.0._module._linear_layers.0.weight\n",
      "2021-01-31 18:33:27,089 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.genia2__ner_labels.0._module._linear_layers.1.bias\n",
      "2021-01-31 18:33:27,090 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.genia2__ner_labels.0._module._linear_layers.1.weight\n",
      "2021-01-31 18:33:27,090 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.genia2__ner_labels.1._module.bias\n",
      "2021-01-31 18:33:27,090 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.genia2__ner_labels.1._module.weight\n",
      "2021-01-31 18:33:27,090 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
      "2021-01-31 18:33:27,090 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
      "2021-01-31 18:33:27,090 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
      "2021-01-31 18:33:27,091 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
      "2021-01-31 18:33:27,091 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
      "2021-01-31 18:33:27,091 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
      "2021-01-31 18:33:27,091 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
      "2021-01-31 18:33:27,091 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
      "2021-01-31 18:33:27,091 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
      "2021-01-31 18:33:27,091 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
      "2021-01-31 18:33:27,091 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
      "2021-01-31 18:33:27,091 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
      "2021-01-31 18:33:27,091 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
      "2021-01-31 18:33:27,091 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
      "2021-01-31 18:33:27,092 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
      "2021-01-31 18:33:27,092 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
      "2021-01-31 18:33:27,092 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
      "2021-01-31 18:33:27,092 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
      "2021-01-31 18:33:27,092 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
      "2021-01-31 18:33:27,092 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
      "2021-01-31 18:33:27,092 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
      "2021-01-31 18:33:27,092 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
      "2021-01-31 18:33:27,093 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
      "2021-01-31 18:33:27,093 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
      "2021-01-31 18:33:27,093 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
      "2021-01-31 18:33:27,093 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
      "2021-01-31 18:33:27,093 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
      "2021-01-31 18:33:27,093 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
      "2021-01-31 18:33:27,093 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
      "2021-01-31 18:33:27,093 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
      "2021-01-31 18:33:27,093 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
      "2021-01-31 18:33:27,094 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
      "2021-01-31 18:33:27,094 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
      "2021-01-31 18:33:27,094 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
      "2021-01-31 18:33:27,094 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
      "2021-01-31 18:33:27,094 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
      "2021-01-31 18:33:27,094 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
      "2021-01-31 18:33:27,094 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
      "2021-01-31 18:33:27,094 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
      "2021-01-31 18:33:27,094 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
      "2021-01-31 18:33:27,094 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
      "2021-01-31 18:33:27,094 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
      "2021-01-31 18:33:27,095 - INFO - allennlp.common.params - trainer.type = gradient_descent\n",
      "2021-01-31 18:33:27,095 - INFO - allennlp.common.params - trainer.patience = None\n",
      "2021-01-31 18:33:27,095 - INFO - allennlp.common.params - trainer.validation_metric = +MEAN__ner_f1\n",
      "2021-01-31 18:33:27,095 - INFO - allennlp.common.params - trainer.num_epochs = 3\n",
      "2021-01-31 18:33:27,095 - INFO - allennlp.common.params - trainer.cuda_device = 0\n",
      "2021-01-31 18:33:27,095 - INFO - allennlp.common.params - trainer.grad_norm = 5\n",
      "2021-01-31 18:33:27,095 - INFO - allennlp.common.params - trainer.grad_clipping = None\n",
      "2021-01-31 18:33:27,095 - INFO - allennlp.common.params - trainer.distributed = False\n",
      "2021-01-31 18:33:27,095 - INFO - allennlp.common.params - trainer.world_size = 1\n",
      "2021-01-31 18:33:27,095 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1\n",
      "2021-01-31 18:33:27,095 - INFO - allennlp.common.params - trainer.use_amp = False\n",
      "2021-01-31 18:33:27,095 - INFO - allennlp.common.params - trainer.no_grad = None\n",
      "2021-01-31 18:33:27,096 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n",
      "2021-01-31 18:33:27,096 - INFO - allennlp.common.params - trainer.tensorboard_writer = <allennlp.common.lazy.Lazy object at 0x7f50f4136d50>\n",
      "2021-01-31 18:33:27,096 - INFO - allennlp.common.params - trainer.moving_average = None\n",
      "2021-01-31 18:33:27,096 - INFO - allennlp.common.params - trainer.batch_callbacks = None\n",
      "2021-01-31 18:33:27,096 - INFO - allennlp.common.params - trainer.epoch_callbacks = None\n",
      "2021-01-31 18:33:27,096 - INFO - allennlp.common.params - trainer.end_callbacks = None\n",
      "2021-01-31 18:33:27,096 - INFO - allennlp.common.params - trainer.trainer_callbacks = None\n",
      "2021-01-31 18:33:35,976 - INFO - allennlp.common.params - trainer.optimizer.type = adamw\n",
      "2021-01-31 18:33:35,977 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.001\n",
      "2021-01-31 18:33:35,977 - INFO - allennlp.common.params - trainer.optimizer.betas = (0.9, 0.999)\n",
      "2021-01-31 18:33:35,977 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08\n",
      "2021-01-31 18:33:35,977 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0\n",
      "2021-01-31 18:33:35,977 - INFO - allennlp.common.params - trainer.optimizer.amsgrad = False\n",
      "2021-01-31 18:33:35,978 - INFO - allennlp.training.optimizers - Done constructing parameter groups.\n",
      "2021-01-31 18:33:35,978 - INFO - allennlp.training.optimizers - Group 0: ['_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight'], {'finetune': True, 'lr': 5e-05, 'weight_decay': 0.01}\n",
      "2021-01-31 18:33:35,979 - INFO - allennlp.training.optimizers - Group 1: ['_ner._ner_scorers.genia2__ner_labels.0._module._linear_layers.0.weight', '_coref._mention_pruner._scorer.0._module._linear_layers.1.bias', '_endpoint_span_extractor._span_width_embedding.weight', '_ner._ner_scorers.genia2__ner_labels.0._module._linear_layers.0.bias', '_coref._antecedent_scorer._module.weight', '_ner._ner_scorers.genia2__ner_labels.0._module._linear_layers.1.weight', '_coref._f_network._linear_layers.0.weight', '_coref._mention_pruner._scorer.1._module.bias', '_ner._ner_scorers.genia2__ner_labels.1._module.weight', '_ner._ner_scorers.genia2__ner_labels.1._module.bias', '_coref._mention_pruner._scorer.1._module.weight', '_ner._ner_scorers.genia2__ner_labels.0._module._linear_layers.1.bias', '_coref._mention_pruner._scorer.0._module._linear_layers.1.weight', '_coref._f_network._linear_layers.0.bias', '_coref._mention_pruner._scorer.0._module._linear_layers.0.weight', '_coref._antecedent_feedforward._module._linear_layers.0.bias', '_coref._antecedent_feedforward._module._linear_layers.0.weight', '_coref._antecedent_scorer._module.bias', '_coref._antecedent_feedforward._module._linear_layers.1.bias', '_events._distance_embedding.weight', '_coref._distance_embedding.weight', '_coref._antecedent_feedforward._module._linear_layers.1.weight', '_coref._mention_pruner._scorer.0._module._linear_layers.0.bias'], {}\n",
      "2021-01-31 18:33:35,980 - INFO - allennlp.training.optimizers - Number of trainable parameters: 115566085\n",
      "2021-01-31 18:33:35,981 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):\n",
      "2021-01-31 18:33:35,982 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):\n",
      "2021-01-31 18:33:35,983 - INFO - allennlp.common.util - _endpoint_span_extractor._span_width_embedding.weight\n",
      "2021-01-31 18:33:35,983 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
      "2021-01-31 18:33:35,983 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
      "2021-01-31 18:33:35,983 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
      "2021-01-31 18:33:35,983 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
      "2021-01-31 18:33:35,983 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
      "2021-01-31 18:33:35,983 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
      "2021-01-31 18:33:35,983 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
      "2021-01-31 18:33:35,983 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
      "2021-01-31 18:33:35,983 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
      "2021-01-31 18:33:35,983 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
      "2021-01-31 18:33:35,983 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
      "2021-01-31 18:33:35,983 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
      "2021-01-31 18:33:35,983 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
      "2021-01-31 18:33:35,983 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,983 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,983 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
      "2021-01-31 18:33:35,983 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
      "2021-01-31 18:33:35,984 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
      "2021-01-31 18:33:35,984 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
      "2021-01-31 18:33:35,984 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,984 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,984 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
      "2021-01-31 18:33:35,984 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
      "2021-01-31 18:33:35,984 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
      "2021-01-31 18:33:35,984 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
      "2021-01-31 18:33:35,984 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
      "2021-01-31 18:33:35,984 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
      "2021-01-31 18:33:35,984 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
      "2021-01-31 18:33:35,984 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
      "2021-01-31 18:33:35,984 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,984 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,984 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
      "2021-01-31 18:33:35,984 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
      "2021-01-31 18:33:35,984 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
      "2021-01-31 18:33:35,984 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
      "2021-01-31 18:33:35,984 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,985 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,985 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
      "2021-01-31 18:33:35,985 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
      "2021-01-31 18:33:35,985 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
      "2021-01-31 18:33:35,985 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
      "2021-01-31 18:33:35,985 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
      "2021-01-31 18:33:35,985 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
      "2021-01-31 18:33:35,985 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
      "2021-01-31 18:33:35,985 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
      "2021-01-31 18:33:35,985 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,985 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,985 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
      "2021-01-31 18:33:35,985 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
      "2021-01-31 18:33:35,985 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
      "2021-01-31 18:33:35,986 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
      "2021-01-31 18:33:35,986 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,986 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,986 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
      "2021-01-31 18:33:35,986 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
      "2021-01-31 18:33:35,986 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
      "2021-01-31 18:33:35,986 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
      "2021-01-31 18:33:35,986 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
      "2021-01-31 18:33:35,986 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
      "2021-01-31 18:33:35,986 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
      "2021-01-31 18:33:35,986 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
      "2021-01-31 18:33:35,986 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,986 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,986 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
      "2021-01-31 18:33:35,986 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
      "2021-01-31 18:33:35,986 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
      "2021-01-31 18:33:35,986 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
      "2021-01-31 18:33:35,986 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,986 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,986 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
      "2021-01-31 18:33:35,987 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
      "2021-01-31 18:33:35,987 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
      "2021-01-31 18:33:35,987 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
      "2021-01-31 18:33:35,987 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
      "2021-01-31 18:33:35,987 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
      "2021-01-31 18:33:35,987 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
      "2021-01-31 18:33:35,987 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
      "2021-01-31 18:33:35,987 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,987 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,987 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
      "2021-01-31 18:33:35,987 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
      "2021-01-31 18:33:35,987 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
      "2021-01-31 18:33:35,987 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
      "2021-01-31 18:33:35,987 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,987 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,987 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
      "2021-01-31 18:33:35,987 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
      "2021-01-31 18:33:35,987 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
      "2021-01-31 18:33:35,987 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
      "2021-01-31 18:33:35,988 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
      "2021-01-31 18:33:35,988 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
      "2021-01-31 18:33:35,988 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
      "2021-01-31 18:33:35,988 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
      "2021-01-31 18:33:35,988 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,988 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,988 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
      "2021-01-31 18:33:35,988 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
      "2021-01-31 18:33:35,988 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
      "2021-01-31 18:33:35,988 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
      "2021-01-31 18:33:35,988 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,988 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,988 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
      "2021-01-31 18:33:35,988 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
      "2021-01-31 18:33:35,988 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
      "2021-01-31 18:33:35,988 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
      "2021-01-31 18:33:35,988 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
      "2021-01-31 18:33:35,988 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
      "2021-01-31 18:33:35,988 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
      "2021-01-31 18:33:35,988 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
      "2021-01-31 18:33:35,989 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,989 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,989 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
      "2021-01-31 18:33:35,989 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
      "2021-01-31 18:33:35,989 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
      "2021-01-31 18:33:35,989 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
      "2021-01-31 18:33:35,989 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,989 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,989 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
      "2021-01-31 18:33:35,989 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
      "2021-01-31 18:33:35,989 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
      "2021-01-31 18:33:35,989 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
      "2021-01-31 18:33:35,989 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
      "2021-01-31 18:33:35,989 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
      "2021-01-31 18:33:35,989 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
      "2021-01-31 18:33:35,989 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
      "2021-01-31 18:33:35,989 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,989 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,989 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
      "2021-01-31 18:33:35,989 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
      "2021-01-31 18:33:35,990 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
      "2021-01-31 18:33:35,990 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
      "2021-01-31 18:33:35,990 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,990 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,990 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
      "2021-01-31 18:33:35,990 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
      "2021-01-31 18:33:35,990 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
      "2021-01-31 18:33:35,990 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
      "2021-01-31 18:33:35,990 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
      "2021-01-31 18:33:35,990 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
      "2021-01-31 18:33:35,990 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
      "2021-01-31 18:33:35,990 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
      "2021-01-31 18:33:35,990 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,990 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,990 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
      "2021-01-31 18:33:35,990 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
      "2021-01-31 18:33:35,990 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
      "2021-01-31 18:33:35,990 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
      "2021-01-31 18:33:35,990 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,990 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,991 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
      "2021-01-31 18:33:35,991 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
      "2021-01-31 18:33:35,991 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
      "2021-01-31 18:33:35,991 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
      "2021-01-31 18:33:35,991 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
      "2021-01-31 18:33:35,991 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
      "2021-01-31 18:33:35,991 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
      "2021-01-31 18:33:35,991 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
      "2021-01-31 18:33:35,991 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,991 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,991 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
      "2021-01-31 18:33:35,991 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
      "2021-01-31 18:33:35,991 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
      "2021-01-31 18:33:35,991 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
      "2021-01-31 18:33:35,991 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,991 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,991 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
      "2021-01-31 18:33:35,991 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
      "2021-01-31 18:33:35,991 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
      "2021-01-31 18:33:35,992 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
      "2021-01-31 18:33:35,992 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
      "2021-01-31 18:33:35,992 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
      "2021-01-31 18:33:35,992 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
      "2021-01-31 18:33:35,992 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
      "2021-01-31 18:33:35,992 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,992 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,992 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
      "2021-01-31 18:33:35,992 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
      "2021-01-31 18:33:35,992 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
      "2021-01-31 18:33:35,992 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
      "2021-01-31 18:33:35,992 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,992 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,992 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
      "2021-01-31 18:33:35,992 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
      "2021-01-31 18:33:35,992 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
      "2021-01-31 18:33:35,992 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
      "2021-01-31 18:33:35,992 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
      "2021-01-31 18:33:35,993 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
      "2021-01-31 18:33:35,993 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
      "2021-01-31 18:33:35,993 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
      "2021-01-31 18:33:35,993 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,993 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,993 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
      "2021-01-31 18:33:35,993 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
      "2021-01-31 18:33:35,993 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
      "2021-01-31 18:33:35,993 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
      "2021-01-31 18:33:35,993 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2021-01-31 18:33:35,993 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2021-01-31 18:33:35,993 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight\n",
      "2021-01-31 18:33:35,993 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias\n",
      "2021-01-31 18:33:35,993 - INFO - allennlp.common.util - _ner._ner_scorers.genia2__ner_labels.0._module._linear_layers.0.weight\n",
      "2021-01-31 18:33:35,993 - INFO - allennlp.common.util - _ner._ner_scorers.genia2__ner_labels.0._module._linear_layers.0.bias\n",
      "2021-01-31 18:33:35,993 - INFO - allennlp.common.util - _ner._ner_scorers.genia2__ner_labels.0._module._linear_layers.1.weight\n",
      "2021-01-31 18:33:35,993 - INFO - allennlp.common.util - _ner._ner_scorers.genia2__ner_labels.0._module._linear_layers.1.bias\n",
      "2021-01-31 18:33:35,994 - INFO - allennlp.common.util - _ner._ner_scorers.genia2__ner_labels.1._module.weight\n",
      "2021-01-31 18:33:35,994 - INFO - allennlp.common.util - _ner._ner_scorers.genia2__ner_labels.1._module.bias\n",
      "2021-01-31 18:33:35,994 - INFO - allennlp.common.util - _coref._distance_embedding.weight\n",
      "2021-01-31 18:33:35,994 - INFO - allennlp.common.util - _coref._antecedent_feedforward._module._linear_layers.0.weight\n",
      "2021-01-31 18:33:35,994 - INFO - allennlp.common.util - _coref._antecedent_feedforward._module._linear_layers.0.bias\n",
      "2021-01-31 18:33:35,994 - INFO - allennlp.common.util - _coref._antecedent_feedforward._module._linear_layers.1.weight\n",
      "2021-01-31 18:33:35,994 - INFO - allennlp.common.util - _coref._antecedent_feedforward._module._linear_layers.1.bias\n",
      "2021-01-31 18:33:35,994 - INFO - allennlp.common.util - _coref._mention_pruner._scorer.0._module._linear_layers.0.weight\n",
      "2021-01-31 18:33:35,994 - INFO - allennlp.common.util - _coref._mention_pruner._scorer.0._module._linear_layers.0.bias\n",
      "2021-01-31 18:33:35,994 - INFO - allennlp.common.util - _coref._mention_pruner._scorer.0._module._linear_layers.1.weight\n",
      "2021-01-31 18:33:35,994 - INFO - allennlp.common.util - _coref._mention_pruner._scorer.0._module._linear_layers.1.bias\n",
      "2021-01-31 18:33:35,994 - INFO - allennlp.common.util - _coref._mention_pruner._scorer.1._module.weight\n",
      "2021-01-31 18:33:35,994 - INFO - allennlp.common.util - _coref._mention_pruner._scorer.1._module.bias\n",
      "2021-01-31 18:33:35,994 - INFO - allennlp.common.util - _coref._antecedent_scorer._module.weight\n",
      "2021-01-31 18:33:35,994 - INFO - allennlp.common.util - _coref._antecedent_scorer._module.bias\n",
      "2021-01-31 18:33:35,994 - INFO - allennlp.common.util - _coref._f_network._linear_layers.0.weight\n",
      "2021-01-31 18:33:35,994 - INFO - allennlp.common.util - _coref._f_network._linear_layers.0.bias\n",
      "2021-01-31 18:33:35,994 - INFO - allennlp.common.util - _events._distance_embedding.weight\n",
      "2021-01-31 18:33:35,995 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = slanted_triangular\n",
      "2021-01-31 18:33:35,995 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.cut_frac = 0.1\n",
      "2021-01-31 18:33:35,995 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.ratio = 32\n",
      "2021-01-31 18:33:35,995 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.last_epoch = -1\n",
      "2021-01-31 18:33:35,995 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.gradual_unfreezing = False\n",
      "2021-01-31 18:33:35,995 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.discriminative_fine_tuning = False\n",
      "2021-01-31 18:33:35,995 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.decay_factor = 0.38\n",
      "2021-01-31 18:33:35,995 - INFO - allennlp.common.params - trainer.checkpointer.type = default\n",
      "2021-01-31 18:33:35,995 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None\n",
      "2021-01-31 18:33:35,996 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 3\n",
      "2021-01-31 18:33:35,996 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None\n",
      "2021-01-31 18:33:35,996 - INFO - allennlp.common.params - summary_interval = 100\n",
      "2021-01-31 18:33:35,996 - INFO - allennlp.common.params - histogram_interval = None\n",
      "2021-01-31 18:33:35,996 - INFO - allennlp.common.params - batch_size_interval = None\n",
      "2021-01-31 18:33:35,996 - INFO - allennlp.common.params - should_log_parameter_statistics = True\n",
      "2021-01-31 18:33:35,996 - INFO - allennlp.common.params - should_log_learning_rate = False\n",
      "2021-01-31 18:33:35,996 - INFO - allennlp.common.params - get_batch_num_total = None\n",
      "2021-01-31 18:33:35,998 - WARNING - allennlp.training.trainer - You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n",
      "2021-01-31 18:33:35,998 - INFO - allennlp.training.trainer - Beginning training.\n",
      "2021-01-31 18:33:35,998 - INFO - allennlp.training.trainer - Epoch 0/2\n",
      "2021-01-31 18:33:35,998 - INFO - allennlp.training.trainer - Worker 0 memory usage: 3.6G\n",
      "2021-01-31 18:33:35,998 - INFO - allennlp.training.trainer - GPU 0 memory usage: 442M\n",
      "2021-01-31 18:33:35,999 - INFO - allennlp.training.trainer - Training\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]2021-01-31 18:33:37,012 - WARNING - allennlp.training.util - Metrics with names beginning with \"_\" will not be logged to the tqdm progress bar.\n",
      "MEAN__ner_precision: 0.0177, MEAN__ner_recall: 0.1140, MEAN__ner_f1: 0.0307, batch_loss: 79.0672, loss: 973.8378 ||: 100%|##########| 100/100 [00:42<00:00,  2.34it/s]  \n",
      "2021-01-31 18:34:19,619 - INFO - allennlp.training.trainer - Validating\n",
      "MEAN__ner_precision: 0.6097, MEAN__ner_recall: 0.3995, MEAN__ner_f1: 0.4827, batch_loss: 83.3618, loss: 90.4736 ||: 100%|##########| 100/100 [00:16<00:00,  5.95it/s] \n",
      "2021-01-31 18:34:36,431 - INFO - allennlp.training.tensorboard_writer -                                 Training |  Validation\n",
      "2021-01-31 18:34:36,431 - INFO - allennlp.training.tensorboard_writer - MEAN__ner_f1                |     0.031  |     0.483\n",
      "2021-01-31 18:34:36,432 - INFO - allennlp.training.tensorboard_writer - MEAN__ner_precision         |     0.018  |     0.610\n",
      "2021-01-31 18:34:36,433 - INFO - allennlp.training.tensorboard_writer - MEAN__ner_recall            |     0.114  |     0.400\n",
      "2021-01-31 18:34:36,433 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_class_f1         |     0.000  |     0.000\n",
      "2021-01-31 18:34:36,434 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_class_precision  |     0.000  |     0.000\n",
      "2021-01-31 18:34:36,434 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_class_recall     |     0.000  |     0.000\n",
      "2021-01-31 18:34:36,435 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_id_f1            |     0.000  |     0.000\n",
      "2021-01-31 18:34:36,436 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_id_precision     |     0.000  |     0.000\n",
      "2021-01-31 18:34:36,437 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_id_recall        |     0.000  |     0.000\n",
      "2021-01-31 18:34:36,437 - INFO - allennlp.training.tensorboard_writer - _MEAN__relation_f1          |     0.000  |     0.000\n",
      "2021-01-31 18:34:36,437 - INFO - allennlp.training.tensorboard_writer - _MEAN__relation_precision   |     0.000  |     0.000\n",
      "2021-01-31 18:34:36,438 - INFO - allennlp.training.tensorboard_writer - _MEAN__relation_recall      |     0.000  |     0.000\n",
      "2021-01-31 18:34:36,439 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_class_f1        |     0.000  |     0.000\n",
      "2021-01-31 18:34:36,439 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_class_precision |     0.000  |     0.000\n",
      "2021-01-31 18:34:36,440 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_class_recall    |     0.000  |     0.000\n",
      "2021-01-31 18:34:36,440 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_id_f1           |     0.000  |     0.000\n",
      "2021-01-31 18:34:36,441 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_id_precision    |     0.000  |     0.000\n",
      "2021-01-31 18:34:36,441 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_id_recall       |     0.000  |     0.000\n",
      "2021-01-31 18:34:36,442 - INFO - allennlp.training.tensorboard_writer - _coref_f1                   |     0.002  |     0.000\n",
      "2021-01-31 18:34:36,442 - INFO - allennlp.training.tensorboard_writer - _coref_mention_recall       |     0.116  |     0.409\n",
      "2021-01-31 18:34:36,442 - INFO - allennlp.training.tensorboard_writer - _coref_precision            |     0.010  |     0.000\n",
      "2021-01-31 18:34:36,443 - INFO - allennlp.training.tensorboard_writer - _coref_recall               |     0.001  |     0.000\n",
      "2021-01-31 18:34:36,443 - INFO - allennlp.training.tensorboard_writer - _genia2__ner_f1             |     0.031  |     0.483\n",
      "2021-01-31 18:34:36,445 - INFO - allennlp.training.tensorboard_writer - _genia2__ner_precision      |     0.018  |     0.610\n",
      "2021-01-31 18:34:36,445 - INFO - allennlp.training.tensorboard_writer - _genia2__ner_recall         |     0.114  |     0.400\n",
      "2021-01-31 18:34:36,445 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB             |   441.941  |       N/A\n",
      "2021-01-31 18:34:36,446 - INFO - allennlp.training.tensorboard_writer - loss                        |   973.838  |    90.474\n",
      "2021-01-31 18:34:36,446 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB          |  3663.406  |       N/A\n",
      "2021-01-31 18:34:38,026 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'models/genia2/best.th'.\n",
      "2021-01-31 18:34:38,482 - INFO - allennlp.training.trainer - Epoch duration: 0:01:02.484470\n",
      "2021-01-31 18:34:38,483 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:02:04\n",
      "2021-01-31 18:34:38,483 - INFO - allennlp.training.trainer - Epoch 1/2\n",
      "2021-01-31 18:34:38,483 - INFO - allennlp.training.trainer - Worker 0 memory usage: 3.6G\n",
      "2021-01-31 18:34:38,483 - INFO - allennlp.training.trainer - GPU 0 memory usage: 4.4G\n",
      "2021-01-31 18:34:38,485 - INFO - allennlp.training.trainer - Training\n",
      "MEAN__ner_precision: 0.6631, MEAN__ner_recall: 0.4912, MEAN__ner_f1: 0.5643, batch_loss: 73.6951, loss: 79.5085 ||: 100%|##########| 100/100 [00:39<00:00,  2.51it/s] \n",
      "2021-01-31 18:35:19,202 - INFO - allennlp.training.trainer - Validating\n",
      "MEAN__ner_precision: 0.6803, MEAN__ner_recall: 0.6032, MEAN__ner_f1: 0.6394, batch_loss: 95.0889, loss: 78.4411 ||: 100%|##########| 100/100 [00:15<00:00,  6.46it/s]\n",
      "2021-01-31 18:35:34,682 - INFO - allennlp.training.tensorboard_writer -                                 Training |  Validation\n",
      "2021-01-31 18:35:34,683 - INFO - allennlp.training.tensorboard_writer - MEAN__ner_f1                |     0.564  |     0.639\n",
      "2021-01-31 18:35:34,683 - INFO - allennlp.training.tensorboard_writer - MEAN__ner_precision         |     0.663  |     0.680\n",
      "2021-01-31 18:35:34,683 - INFO - allennlp.training.tensorboard_writer - MEAN__ner_recall            |     0.491  |     0.603\n",
      "2021-01-31 18:35:34,684 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_class_f1         |     0.000  |     0.000\n",
      "2021-01-31 18:35:34,684 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_class_precision  |     0.000  |     0.000\n",
      "2021-01-31 18:35:34,685 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_class_recall     |     0.000  |     0.000\n",
      "2021-01-31 18:35:34,685 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_id_f1            |     0.000  |     0.000\n",
      "2021-01-31 18:35:34,686 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_id_precision     |     0.000  |     0.000\n",
      "2021-01-31 18:35:34,686 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_id_recall        |     0.000  |     0.000\n",
      "2021-01-31 18:35:34,686 - INFO - allennlp.training.tensorboard_writer - _MEAN__relation_f1          |     0.000  |     0.000\n",
      "2021-01-31 18:35:34,687 - INFO - allennlp.training.tensorboard_writer - _MEAN__relation_precision   |     0.000  |     0.000\n",
      "2021-01-31 18:35:34,688 - INFO - allennlp.training.tensorboard_writer - _MEAN__relation_recall      |     0.000  |     0.000\n",
      "2021-01-31 18:35:34,689 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_class_f1        |     0.000  |     0.000\n",
      "2021-01-31 18:35:34,689 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_class_precision |     0.000  |     0.000\n",
      "2021-01-31 18:35:34,690 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_class_recall    |     0.000  |     0.000\n",
      "2021-01-31 18:35:34,690 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_id_f1           |     0.000  |     0.000\n",
      "2021-01-31 18:35:34,692 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_id_precision    |     0.000  |     0.000\n",
      "2021-01-31 18:35:34,692 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_id_recall       |     0.000  |     0.000\n",
      "2021-01-31 18:35:34,693 - INFO - allennlp.training.tensorboard_writer - _coref_f1                   |     0.005  |     0.000\n",
      "2021-01-31 18:35:34,693 - INFO - allennlp.training.tensorboard_writer - _coref_mention_recall       |     0.182  |     0.432\n",
      "2021-01-31 18:35:34,695 - INFO - allennlp.training.tensorboard_writer - _coref_precision            |     0.374  |     0.000\n",
      "2021-01-31 18:35:34,695 - INFO - allennlp.training.tensorboard_writer - _coref_recall               |     0.003  |     0.000\n",
      "2021-01-31 18:35:34,696 - INFO - allennlp.training.tensorboard_writer - _genia2__ner_f1             |     0.564  |     0.639\n",
      "2021-01-31 18:35:34,696 - INFO - allennlp.training.tensorboard_writer - _genia2__ner_precision      |     0.663  |     0.680\n",
      "2021-01-31 18:35:34,697 - INFO - allennlp.training.tensorboard_writer - _genia2__ner_recall         |     0.491  |     0.603\n",
      "2021-01-31 18:35:34,698 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB             |  4534.340  |       N/A\n",
      "2021-01-31 18:35:34,698 - INFO - allennlp.training.tensorboard_writer - loss                        |    79.508  |    78.441\n",
      "2021-01-31 18:35:34,699 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB          |  3663.406  |       N/A\n",
      "2021-01-31 18:35:36,294 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'models/genia2/best.th'.\n",
      "2021-01-31 18:35:44,349 - INFO - allennlp.training.trainer - Epoch duration: 0:01:05.865987\n",
      "2021-01-31 18:35:44,349 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:01:04\n",
      "2021-01-31 18:35:44,349 - INFO - allennlp.training.trainer - Epoch 2/2\n",
      "2021-01-31 18:35:44,349 - INFO - allennlp.training.trainer - Worker 0 memory usage: 3.6G\n",
      "2021-01-31 18:35:44,350 - INFO - allennlp.training.trainer - GPU 0 memory usage: 4.4G\n",
      "2021-01-31 18:35:44,352 - INFO - allennlp.training.trainer - Training\n",
      "MEAN__ner_precision: 0.7422, MEAN__ner_recall: 0.6447, MEAN__ner_f1: 0.6900, batch_loss: 27.6446, loss: 53.2437 ||: 100%|##########| 100/100 [00:40<00:00,  2.49it/s]\n",
      "2021-01-31 18:36:25,315 - INFO - allennlp.training.trainer - Validating\n",
      "MEAN__ner_precision: 0.6411, MEAN__ner_recall: 0.7152, MEAN__ner_f1: 0.6761, batch_loss: 63.8705, loss: 67.9814 ||: 100%|##########| 100/100 [00:15<00:00,  6.28it/s]\n",
      "2021-01-31 18:36:41,233 - INFO - allennlp.training.tensorboard_writer -                                 Training |  Validation\n",
      "2021-01-31 18:36:41,234 - INFO - allennlp.training.tensorboard_writer - MEAN__ner_f1                |     0.690  |     0.676\n",
      "2021-01-31 18:36:41,234 - INFO - allennlp.training.tensorboard_writer - MEAN__ner_precision         |     0.742  |     0.641\n",
      "2021-01-31 18:36:41,235 - INFO - allennlp.training.tensorboard_writer - MEAN__ner_recall            |     0.645  |     0.715\n",
      "2021-01-31 18:36:41,236 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_class_f1         |     0.000  |     0.000\n",
      "2021-01-31 18:36:41,237 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_class_precision  |     0.000  |     0.000\n",
      "2021-01-31 18:36:41,238 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_class_recall     |     0.000  |     0.000\n",
      "2021-01-31 18:36:41,238 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_id_f1            |     0.000  |     0.000\n",
      "2021-01-31 18:36:41,239 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_id_precision     |     0.000  |     0.000\n",
      "2021-01-31 18:36:41,240 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_id_recall        |     0.000  |     0.000\n",
      "2021-01-31 18:36:41,240 - INFO - allennlp.training.tensorboard_writer - _MEAN__relation_f1          |     0.000  |     0.000\n",
      "2021-01-31 18:36:41,241 - INFO - allennlp.training.tensorboard_writer - _MEAN__relation_precision   |     0.000  |     0.000\n",
      "2021-01-31 18:36:41,241 - INFO - allennlp.training.tensorboard_writer - _MEAN__relation_recall      |     0.000  |     0.000\n",
      "2021-01-31 18:36:41,242 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_class_f1        |     0.000  |     0.000\n",
      "2021-01-31 18:36:41,242 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_class_precision |     0.000  |     0.000\n",
      "2021-01-31 18:36:41,243 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_class_recall    |     0.000  |     0.000\n",
      "2021-01-31 18:36:41,243 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_id_f1           |     0.000  |     0.000\n",
      "2021-01-31 18:36:41,244 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_id_precision    |     0.000  |     0.000\n",
      "2021-01-31 18:36:41,245 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_id_recall       |     0.000  |     0.000\n",
      "2021-01-31 18:36:41,246 - INFO - allennlp.training.tensorboard_writer - _coref_f1                   |     0.002  |     0.003\n",
      "2021-01-31 18:36:41,246 - INFO - allennlp.training.tensorboard_writer - _coref_mention_recall       |     0.121  |     0.393\n",
      "2021-01-31 18:36:41,247 - INFO - allennlp.training.tensorboard_writer - _coref_precision            |     0.508  |     0.696\n",
      "2021-01-31 18:36:41,247 - INFO - allennlp.training.tensorboard_writer - _coref_recall               |     0.001  |     0.002\n",
      "2021-01-31 18:36:41,248 - INFO - allennlp.training.tensorboard_writer - _genia2__ner_f1             |     0.690  |     0.676\n",
      "2021-01-31 18:36:41,249 - INFO - allennlp.training.tensorboard_writer - _genia2__ner_precision      |     0.742  |     0.641\n",
      "2021-01-31 18:36:41,249 - INFO - allennlp.training.tensorboard_writer - _genia2__ner_recall         |     0.645  |     0.715\n",
      "2021-01-31 18:36:41,250 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB             |  4534.649  |       N/A\n",
      "2021-01-31 18:36:41,250 - INFO - allennlp.training.tensorboard_writer - loss                        |    53.244  |    67.981\n",
      "2021-01-31 18:36:41,251 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB          |  3663.406  |       N/A\n",
      "2021-01-31 18:36:43,057 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'models/genia2/best.th'.\n",
      "2021-01-31 18:36:49,645 - INFO - allennlp.training.trainer - Epoch duration: 0:01:05.295794\n",
      "2021-01-31 18:36:49,646 - INFO - allennlp.training.checkpointer - loading best weights\n",
      "2021-01-31 18:36:50,108 - INFO - allennlp.commands.train - To evaluate on the test set after training, pass the 'evaluate_on_test' flag, or use the 'allennlp evaluate' command.\n",
      "2021-01-31 18:36:50,108 - INFO - allennlp.common.util - Metrics: {\n",
      "  \"best_epoch\": 2,\n",
      "  \"peak_worker_0_memory_MB\": 3663.40625,\n",
      "  \"peak_gpu_0_memory_MB\": 4534.64892578125,\n",
      "  \"training_duration\": \"0:03:05.252939\",\n",
      "  \"training_start_epoch\": 0,\n",
      "  \"training_epochs\": 2,\n",
      "  \"epoch\": 2,\n",
      "  \"training__coref_precision\": 0.5079365079365079,\n",
      "  \"training__coref_recall\": 0.0012220153765363695,\n",
      "  \"training__coref_f1\": 0.0024369786073986173,\n",
      "  \"training__coref_mention_recall\": 0.1211453744493392,\n",
      "  \"training__genia2__ner_precision\": 0.7421957207997194,\n",
      "  \"training__genia2__ner_recall\": 0.6447288238878732,\n",
      "  \"training__genia2__ner_f1\": 0.6900375020381542,\n",
      "  \"training_MEAN__ner_precision\": 0.7421957207997194,\n",
      "  \"training_MEAN__ner_recall\": 0.6447288238878732,\n",
      "  \"training_MEAN__ner_f1\": 0.6900375020381542,\n",
      "  \"training__MEAN__relation_precision\": 0,\n",
      "  \"training__MEAN__relation_recall\": 0,\n",
      "  \"training__MEAN__relation_f1\": 0,\n",
      "  \"training__MEAN__trig_id_precision\": 0,\n",
      "  \"training__MEAN__trig_id_recall\": 0,\n",
      "  \"training__MEAN__trig_id_f1\": 0,\n",
      "  \"training__MEAN__trig_class_precision\": 0,\n",
      "  \"training__MEAN__trig_class_recall\": 0,\n",
      "  \"training__MEAN__trig_class_f1\": 0,\n",
      "  \"training__MEAN__arg_id_precision\": 0,\n",
      "  \"training__MEAN__arg_id_recall\": 0,\n",
      "  \"training__MEAN__arg_id_f1\": 0,\n",
      "  \"training__MEAN__arg_class_precision\": 0,\n",
      "  \"training__MEAN__arg_class_recall\": 0,\n",
      "  \"training__MEAN__arg_class_f1\": 0,\n",
      "  \"training_loss\": 53.243693295717236,\n",
      "  \"training_worker_0_memory_MB\": 3663.40625,\n",
      "  \"training_gpu_0_memory_MB\": 4534.64892578125,\n",
      "  \"validation__coref_precision\": 0.6956349206349207,\n",
      "  \"validation__coref_recall\": 0.0015739131326213374,\n",
      "  \"validation__coref_f1\": 0.0031406259565691257,\n",
      "  \"validation__coref_mention_recall\": 0.3932096328464272,\n",
      "  \"validation__genia2__ner_precision\": 0.6410569105691057,\n",
      "  \"validation__genia2__ner_recall\": 0.7151927437641723,\n",
      "  \"validation__genia2__ner_f1\": 0.6760986066452305,\n",
      "  \"validation_MEAN__ner_precision\": 0.6410569105691057,\n",
      "  \"validation_MEAN__ner_recall\": 0.7151927437641723,\n",
      "  \"validation_MEAN__ner_f1\": 0.6760986066452305,\n",
      "  \"validation__MEAN__relation_precision\": 0,\n",
      "  \"validation__MEAN__relation_recall\": 0,\n",
      "  \"validation__MEAN__relation_f1\": 0,\n",
      "  \"validation__MEAN__trig_id_precision\": 0,\n",
      "  \"validation__MEAN__trig_id_recall\": 0,\n",
      "  \"validation__MEAN__trig_id_f1\": 0,\n",
      "  \"validation__MEAN__trig_class_precision\": 0,\n",
      "  \"validation__MEAN__trig_class_recall\": 0,\n",
      "  \"validation__MEAN__trig_class_f1\": 0,\n",
      "  \"validation__MEAN__arg_id_precision\": 0,\n",
      "  \"validation__MEAN__arg_id_recall\": 0,\n",
      "  \"validation__MEAN__arg_id_f1\": 0,\n",
      "  \"validation__MEAN__arg_class_precision\": 0,\n",
      "  \"validation__MEAN__arg_class_recall\": 0,\n",
      "  \"validation__MEAN__arg_class_f1\": 0,\n",
      "  \"validation_loss\": 67.98136608600616,\n",
      "  \"best_validation__coref_precision\": 0.6956349206349207,\n",
      "  \"best_validation__coref_recall\": 0.0015739131326213374,\n",
      "  \"best_validation__coref_f1\": 0.0031406259565691257,\n",
      "  \"best_validation__coref_mention_recall\": 0.3932096328464272,\n",
      "  \"best_validation__genia2__ner_precision\": 0.6410569105691057,\n",
      "  \"best_validation__genia2__ner_recall\": 0.7151927437641723,\n",
      "  \"best_validation__genia2__ner_f1\": 0.6760986066452305,\n",
      "  \"best_validation_MEAN__ner_precision\": 0.6410569105691057,\n",
      "  \"best_validation_MEAN__ner_recall\": 0.7151927437641723,\n",
      "  \"best_validation_MEAN__ner_f1\": 0.6760986066452305,\n",
      "  \"best_validation__MEAN__relation_precision\": 0,\n",
      "  \"best_validation__MEAN__relation_recall\": 0,\n",
      "  \"best_validation__MEAN__relation_f1\": 0,\n",
      "  \"best_validation__MEAN__trig_id_precision\": 0,\n",
      "  \"best_validation__MEAN__trig_id_recall\": 0,\n",
      "  \"best_validation__MEAN__trig_id_f1\": 0,\n",
      "  \"best_validation__MEAN__trig_class_precision\": 0,\n",
      "  \"best_validation__MEAN__trig_class_recall\": 0,\n",
      "  \"best_validation__MEAN__trig_class_f1\": 0,\n",
      "  \"best_validation__MEAN__arg_id_precision\": 0,\n",
      "  \"best_validation__MEAN__arg_id_recall\": 0,\n",
      "  \"best_validation__MEAN__arg_id_f1\": 0,\n",
      "  \"best_validation__MEAN__arg_class_precision\": 0,\n",
      "  \"best_validation__MEAN__arg_class_recall\": 0,\n",
      "  \"best_validation__MEAN__arg_class_f1\": 0,\n",
      "  \"best_validation_loss\": 67.98136608600616\n",
      "}\n",
      "2021-01-31 18:36:50,129 - INFO - allennlp.models.archival - archiving weights and vocabulary to models/genia2/model.tar.gz\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!allennlp train \"training_config/genia2.jsonnet\" \\\n",
    "    --serialization-dir \"models/genia2\" \\\n",
    "    --include-package dygie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-necklace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
