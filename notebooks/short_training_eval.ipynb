{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "norwegian-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scispacy\n",
    "import spacy\n",
    "import ndjson\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-reputation",
   "metadata": {},
   "source": [
    "Make a genia 2 and take only the head of train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "nominated-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = Path(os.getcwd())\n",
    "root_dir = pwd.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "athletic-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "lightweight-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data/genia2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "second-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r data/genia/normalized-data/json-coref-all/* data/genia2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-joshua",
   "metadata": {},
   "source": [
    "How big is train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "beautiful-london",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1568 data/genia2/train.json\n"
     ]
    }
   ],
   "source": [
    "!wc -l data/genia2/train.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-friendship",
   "metadata": {},
   "source": [
    "Lets make smaller versions of all datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "constitutional-dispute",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 100 data/genia2/train.json > data/genia2/train_sample.json\n",
    "!head -n 100 data/genia2/dev.json > data/genia2/dev_sample.json\n",
    "!head -n 100 data/genia2/test.json > data/genia2/test_sample.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-hundred",
   "metadata": {},
   "source": [
    "We need to make the config based on the genia config.\n",
    "I copied the genia config and replaced the data with the samples, then I reduced the epochs to 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-process",
   "metadata": {},
   "source": [
    "Then, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "trying-characteristic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-31 18:04:24,354 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2021-01-31 18:04:24,472 - INFO - allennlp.common.params - include_in_archive = None\n",
      "2021-01-31 18:04:24,472 - INFO - allennlp.common.params - random_seed = 13370\n",
      "2021-01-31 18:04:24,473 - INFO - allennlp.common.params - numpy_seed = 1337\n",
      "2021-01-31 18:04:24,473 - INFO - allennlp.common.params - pytorch_seed = 133\n",
      "2021-01-31 18:04:24,510 - INFO - allennlp.common.checks - Pytorch version: 1.7.1\n",
      "2021-01-31 18:04:24,510 - INFO - allennlp.common.params - type = default\n",
      "2021-01-31 18:04:24,511 - INFO - allennlp.common.params - dataset_reader.type = dygie\n",
      "2021-01-31 18:04:24,511 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
      "2021-01-31 18:04:24,511 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
      "2021-01-31 18:04:24,511 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2021-01-31 18:04:24,511 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2021-01-31 18:04:24,511 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
      "2021-01-31 18:04:24,512 - INFO - allennlp.common.params - dataset_reader.max_span_width = 8\n",
      "2021-01-31 18:04:24,512 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = pretrained_transformer_mismatched\n",
      "2021-01-31 18:04:24,512 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.token_min_padding_length = 0\n",
      "2021-01-31 18:04:24,512 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.model_name = microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\n",
      "2021-01-31 18:04:24,512 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.namespace = tags\n",
      "2021-01-31 18:04:24,512 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_length = 512\n",
      "2021-01-31 18:04:24,512 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.tokenizer_kwargs = None\n",
      "Downloading: 100%|██████████████████████████████| 337/337 [00:00<00:00, 217kB/s]\n",
      "Downloading: 100%|████████████████████████████| 225k/225k [00:00<00:00, 748kB/s]\n",
      "2021-01-31 18:04:38,586 - INFO - allennlp.common.params - train_data_path = data/genia2/train_sample.json\n",
      "2021-01-31 18:04:38,587 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f1d8c2fcb10>\n",
      "2021-01-31 18:04:38,587 - INFO - allennlp.common.params - datasets_for_vocab_creation = None\n",
      "2021-01-31 18:04:38,587 - INFO - allennlp.common.params - validation_dataset_reader = None\n",
      "2021-01-31 18:04:38,587 - INFO - allennlp.common.params - validation_data_path = data/genia2/dev_sample.json\n",
      "2021-01-31 18:04:38,587 - INFO - allennlp.common.params - validation_data_loader = None\n",
      "2021-01-31 18:04:38,587 - INFO - allennlp.common.params - test_data_path = data/genia2/test_sample.json\n",
      "2021-01-31 18:04:38,587 - INFO - allennlp.common.params - evaluate_on_test = False\n",
      "2021-01-31 18:04:38,587 - INFO - allennlp.common.params - batch_weight_key = \n",
      "2021-01-31 18:04:38,587 - INFO - allennlp.training.util - Reading training data from data/genia2/train_sample.json\n",
      "reading instances: 100it [00:01, 66.81it/s]\n",
      "2021-01-31 18:04:40,085 - INFO - allennlp.training.util - Reading validation data from data/genia2/dev_sample.json\n",
      "reading instances: 100it [00:01, 69.12it/s]\n",
      "2021-01-31 18:04:41,532 - INFO - allennlp.training.util - Reading test data from data/genia2/test_sample.json\n",
      "reading instances: 100it [00:01, 85.95it/s]\n",
      "2021-01-31 18:04:42,696 - INFO - allennlp.common.params - type = from_instances\n",
      "2021-01-31 18:04:42,696 - INFO - allennlp.common.params - min_count = None\n",
      "2021-01-31 18:04:42,696 - INFO - allennlp.common.params - max_vocab_size = None\n",
      "2021-01-31 18:04:42,696 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')\n",
      "2021-01-31 18:04:42,696 - INFO - allennlp.common.params - pretrained_files = None\n",
      "2021-01-31 18:04:42,696 - INFO - allennlp.common.params - only_include_pretrained_words = False\n",
      "2021-01-31 18:04:42,696 - INFO - allennlp.common.params - tokens_to_add = None\n",
      "2021-01-31 18:04:42,697 - INFO - allennlp.common.params - min_pretrained_embeddings = None\n",
      "2021-01-31 18:04:42,697 - INFO - allennlp.common.params - padding_token = @@PADDING@@\n",
      "2021-01-31 18:04:42,697 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@\n",
      "2021-01-31 18:04:42,697 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n",
      "building vocab: 300it [00:00, 1142.45it/s]\n",
      "2021-01-31 18:04:42,960 - INFO - allennlp.common.params - model.type = dygie\n",
      "2021-01-31 18:04:42,960 - INFO - allennlp.common.params - model.embedder.type = basic\n",
      "2021-01-31 18:04:42,961 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.type = pretrained_transformer_mismatched\n",
      "2021-01-31 18:04:42,961 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.model_name = microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\n",
      "2021-01-31 18:04:42,961 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.max_length = 512\n",
      "2021-01-31 18:04:42,961 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.train_parameters = True\n",
      "2021-01-31 18:04:42,961 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.last_layer_only = True\n",
      "2021-01-31 18:04:42,961 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.gradient_checkpointing = None\n",
      "2021-01-31 18:04:42,961 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.tokenizer_kwargs = None\n",
      "2021-01-31 18:04:42,961 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.transformer_kwargs = None\n",
      "Downloading: 100%|███████████████████████████| 440M/440M [01:43<00:00, 4.26MB/s]\n",
      "2021-01-31 18:06:30,973 - INFO - allennlp.common.params - model.modules.coref.coref_prop = 2\n",
      "2021-01-31 18:06:30,973 - INFO - allennlp.common.params - model.modules.coref.max_antecedents = 100\n",
      "2021-01-31 18:06:30,973 - INFO - allennlp.common.params - model.modules.coref.spans_per_word = 0.3\n",
      "2021-01-31 18:06:30,973 - INFO - allennlp.common.params - model.modules.events.argument_spans_per_word = 0.8\n",
      "2021-01-31 18:06:30,973 - INFO - allennlp.common.params - model.modules.events.loss_weights.arguments = 1\n",
      "2021-01-31 18:06:30,973 - INFO - allennlp.common.params - model.modules.events.loss_weights.trigger = 0.2\n",
      "2021-01-31 18:06:30,973 - INFO - allennlp.common.params - model.modules.events.trigger_spans_per_word = 0.3\n",
      "2021-01-31 18:06:30,973 - INFO - allennlp.common.params - model.modules.relation.spans_per_word = 0.5\n",
      "2021-01-31 18:06:30,973 - INFO - allennlp.common.params - model.feature_size = 20\n",
      "2021-01-31 18:06:30,973 - INFO - allennlp.common.params - model.max_span_width = 8\n",
      "2021-01-31 18:06:30,973 - INFO - allennlp.common.params - model.target_task = ner\n",
      "2021-01-31 18:06:30,974 - INFO - allennlp.common.params - model.initializer.regexes.0.1.type = xavier_normal\n",
      "2021-01-31 18:06:30,974 - INFO - allennlp.common.params - model.initializer.regexes.0.1.gain = 1.0\n",
      "2021-01-31 18:06:30,974 - INFO - allennlp.common.params - model.initializer.prevent_regexes = None\n",
      "2021-01-31 18:06:30,974 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.type = xavier_normal\n",
      "2021-01-31 18:06:30,975 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.gain = 1.0\n",
      "2021-01-31 18:06:30,975 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.type = xavier_normal\n",
      "2021-01-31 18:06:30,975 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.gain = 1.0\n",
      "2021-01-31 18:06:30,975 - INFO - allennlp.common.params - model.module_initializer.prevent_regexes = None\n",
      "2021-01-31 18:06:30,975 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2021-01-31 18:06:30,975 - INFO - allennlp.common.params - model.display_metrics = None\n",
      "2021-01-31 18:06:30,975 - INFO - allennlp.common.params - ner.regularizer = None\n",
      "2021-01-31 18:06:30,978 - INFO - allennlp.common.params - coref.spans_per_word = 0.3\n",
      "2021-01-31 18:06:30,978 - INFO - allennlp.common.params - coref.max_antecedents = 100\n",
      "2021-01-31 18:06:30,978 - INFO - allennlp.common.params - coref.coref_prop = 2\n",
      "2021-01-31 18:06:30,978 - INFO - allennlp.common.params - coref.coref_prop_dropout_f = 0.0\n",
      "2021-01-31 18:06:30,978 - INFO - allennlp.common.params - coref.regularizer = None\n",
      "2021-01-31 18:06:31,013 - INFO - allennlp.common.params - relation.spans_per_word = 0.5\n",
      "2021-01-31 18:06:31,013 - INFO - allennlp.common.params - relation.positive_label_weight = 1.0\n",
      "2021-01-31 18:06:31,014 - INFO - allennlp.common.params - relation.regularizer = None\n",
      "2021-01-31 18:06:31,014 - INFO - allennlp.common.params - events.trigger_spans_per_word = 0.3\n",
      "2021-01-31 18:06:31,014 - INFO - allennlp.common.params - events.argument_spans_per_word = 0.8\n",
      "2021-01-31 18:06:31,014 - INFO - allennlp.common.params - events.regularizer = None\n",
      "2021-01-31 18:06:31,015 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2021-01-31 18:06:31,015 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.genia__ner_labels.0._module._linear_layers.0.weight using .*weight initializer\n",
      "2021-01-31 18:06:31,017 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.genia__ner_labels.0._module._linear_layers.1.weight using .*weight initializer\n",
      "2021-01-31 18:06:31,017 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.genia__ner_labels.1._module.weight using .*weight initializer\n",
      "2021-01-31 18:06:31,017 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
      "2021-01-31 18:06:31,017 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2021-01-31 18:06:31,017 - INFO - allennlp.nn.initializers -    _ner_scorers.genia__ner_labels.0._module._linear_layers.0.bias\n",
      "2021-01-31 18:06:31,017 - INFO - allennlp.nn.initializers -    _ner_scorers.genia__ner_labels.0._module._linear_layers.1.bias\n",
      "2021-01-31 18:06:31,018 - INFO - allennlp.nn.initializers -    _ner_scorers.genia__ner_labels.1._module.bias\n",
      "2021-01-31 18:06:31,018 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2021-01-31 18:06:31,018 - INFO - allennlp.nn.initializers - Initializing _distance_embedding.weight using .*weight initializer\n",
      "2021-01-31 18:06:31,018 - INFO - allennlp.nn.initializers - Initializing _antecedent_feedforward._module._linear_layers.0.weight using .*weight initializer\n",
      "2021-01-31 18:06:31,024 - INFO - allennlp.nn.initializers - Initializing _antecedent_feedforward._module._linear_layers.1.weight using .*weight initializer\n",
      "2021-01-31 18:06:31,024 - INFO - allennlp.nn.initializers - Initializing _mention_pruner._scorer.0._module._linear_layers.0.weight using .*weight initializer\n",
      "2021-01-31 18:06:31,026 - INFO - allennlp.nn.initializers - Initializing _mention_pruner._scorer.0._module._linear_layers.1.weight using .*weight initializer\n",
      "2021-01-31 18:06:31,026 - INFO - allennlp.nn.initializers - Initializing _mention_pruner._scorer.1._module.weight using .*weight initializer\n",
      "2021-01-31 18:06:31,026 - INFO - allennlp.nn.initializers - Initializing _antecedent_scorer._module.weight using .*weight initializer\n",
      "2021-01-31 18:06:31,027 - INFO - allennlp.nn.initializers - Initializing _f_network._linear_layers.0.weight using .*weight initializer\n",
      "2021-01-31 18:06:31,067 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
      "2021-01-31 18:06:31,068 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2021-01-31 18:06:31,068 - INFO - allennlp.nn.initializers -    _antecedent_feedforward._module._linear_layers.0.bias\n",
      "2021-01-31 18:06:31,068 - INFO - allennlp.nn.initializers -    _antecedent_feedforward._module._linear_layers.1.bias\n",
      "2021-01-31 18:06:31,068 - INFO - allennlp.nn.initializers -    _antecedent_scorer._module.bias\n",
      "2021-01-31 18:06:31,068 - INFO - allennlp.nn.initializers -    _f_network._linear_layers.0.bias\n",
      "2021-01-31 18:06:31,068 - INFO - allennlp.nn.initializers -    _mention_pruner._scorer.0._module._linear_layers.0.bias\n",
      "2021-01-31 18:06:31,068 - INFO - allennlp.nn.initializers -    _mention_pruner._scorer.0._module._linear_layers.1.bias\n",
      "2021-01-31 18:06:31,068 - INFO - allennlp.nn.initializers -    _mention_pruner._scorer.1._module.bias\n",
      "2021-01-31 18:06:31,068 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2021-01-31 18:06:31,068 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
      "2021-01-31 18:06:31,068 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight\n",
      "2021-01-31 18:06:31,068 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2021-01-31 18:06:31,068 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2021-01-31 18:06:31,068 - INFO - allennlp.nn.initializers - Initializing _distance_embedding.weight using .*weight initializer\n",
      "2021-01-31 18:06:31,068 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
      "2021-01-31 18:06:31,068 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2021-01-31 18:06:31,068 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2021-01-31 18:06:31,069 - INFO - allennlp.nn.initializers - Initializing _endpoint_span_extractor._span_width_embedding.weight using _span_width_embedding.weight initializer\n",
      "2021-01-31 18:06:31,071 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2021-01-31 18:06:31,071 - INFO - allennlp.nn.initializers -    _coref._antecedent_feedforward._module._linear_layers.0.bias\n",
      "2021-01-31 18:06:31,071 - INFO - allennlp.nn.initializers -    _coref._antecedent_feedforward._module._linear_layers.0.weight\n",
      "2021-01-31 18:06:31,071 - INFO - allennlp.nn.initializers -    _coref._antecedent_feedforward._module._linear_layers.1.bias\n",
      "2021-01-31 18:06:31,071 - INFO - allennlp.nn.initializers -    _coref._antecedent_feedforward._module._linear_layers.1.weight\n",
      "2021-01-31 18:06:31,071 - INFO - allennlp.nn.initializers -    _coref._antecedent_scorer._module.bias\n",
      "2021-01-31 18:06:31,071 - INFO - allennlp.nn.initializers -    _coref._antecedent_scorer._module.weight\n",
      "2021-01-31 18:06:31,071 - INFO - allennlp.nn.initializers -    _coref._distance_embedding.weight\n",
      "2021-01-31 18:06:31,071 - INFO - allennlp.nn.initializers -    _coref._f_network._linear_layers.0.bias\n",
      "2021-01-31 18:06:31,071 - INFO - allennlp.nn.initializers -    _coref._f_network._linear_layers.0.weight\n",
      "2021-01-31 18:06:31,071 - INFO - allennlp.nn.initializers -    _coref._mention_pruner._scorer.0._module._linear_layers.0.bias\n",
      "2021-01-31 18:06:31,071 - INFO - allennlp.nn.initializers -    _coref._mention_pruner._scorer.0._module._linear_layers.0.weight\n",
      "2021-01-31 18:06:31,071 - INFO - allennlp.nn.initializers -    _coref._mention_pruner._scorer.0._module._linear_layers.1.bias\n",
      "2021-01-31 18:06:31,071 - INFO - allennlp.nn.initializers -    _coref._mention_pruner._scorer.0._module._linear_layers.1.weight\n",
      "2021-01-31 18:06:31,071 - INFO - allennlp.nn.initializers -    _coref._mention_pruner._scorer.1._module.bias\n",
      "2021-01-31 18:06:31,071 - INFO - allennlp.nn.initializers -    _coref._mention_pruner._scorer.1._module.weight\n",
      "2021-01-31 18:06:31,071 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
      "2021-01-31 18:06:31,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
      "2021-01-31 18:06:31,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
      "2021-01-31 18:06:31,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
      "2021-01-31 18:06:31,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
      "2021-01-31 18:06:31,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _events._distance_embedding.weight\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.genia__ner_labels.0._module._linear_layers.0.bias\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.genia__ner_labels.0._module._linear_layers.0.weight\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.genia__ner_labels.0._module._linear_layers.1.bias\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.genia__ner_labels.0._module._linear_layers.1.weight\n",
      "2021-01-31 18:06:31,079 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.genia__ner_labels.1._module.bias\n",
      "2021-01-31 18:06:31,080 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.genia__ner_labels.1._module.weight\n",
      "2021-01-31 18:06:31,080 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
      "2021-01-31 18:06:31,080 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
      "2021-01-31 18:06:31,080 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
      "2021-01-31 18:06:31,080 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
      "2021-01-31 18:06:31,081 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
      "2021-01-31 18:06:31,081 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
      "2021-01-31 18:06:31,081 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
      "2021-01-31 18:06:31,081 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
      "2021-01-31 18:06:31,081 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
      "2021-01-31 18:06:31,081 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
      "2021-01-31 18:06:31,081 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
      "2021-01-31 18:06:31,081 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
      "2021-01-31 18:06:31,081 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
      "2021-01-31 18:06:31,081 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
      "2021-01-31 18:06:31,090 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
      "2021-01-31 18:06:31,090 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
      "2021-01-31 18:06:31,090 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
      "2021-01-31 18:06:31,090 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
      "2021-01-31 18:06:31,090 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
      "2021-01-31 18:06:31,090 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
      "2021-01-31 18:06:31,090 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
      "2021-01-31 18:06:31,090 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
      "2021-01-31 18:06:31,091 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
      "2021-01-31 18:06:31,091 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
      "2021-01-31 18:06:31,091 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
      "2021-01-31 18:06:31,091 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
      "2021-01-31 18:06:31,091 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
      "2021-01-31 18:06:31,091 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
      "2021-01-31 18:06:31,091 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
      "2021-01-31 18:06:31,092 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
      "2021-01-31 18:06:31,092 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
      "2021-01-31 18:06:31,092 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
      "2021-01-31 18:06:31,092 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
      "2021-01-31 18:06:31,092 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
      "2021-01-31 18:06:31,092 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
      "2021-01-31 18:06:31,092 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
      "2021-01-31 18:06:31,092 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
      "2021-01-31 18:06:31,093 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
      "2021-01-31 18:06:31,093 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
      "2021-01-31 18:06:31,093 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
      "2021-01-31 18:06:31,093 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
      "2021-01-31 18:06:31,093 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
      "2021-01-31 18:06:31,093 - INFO - allennlp.common.params - trainer.type = gradient_descent\n",
      "2021-01-31 18:06:31,093 - INFO - allennlp.common.params - trainer.patience = None\n",
      "2021-01-31 18:06:31,094 - INFO - allennlp.common.params - trainer.validation_metric = +MEAN__ner_f1\n",
      "2021-01-31 18:06:31,094 - INFO - allennlp.common.params - trainer.num_epochs = 3\n",
      "2021-01-31 18:06:31,094 - INFO - allennlp.common.params - trainer.cuda_device = 0\n",
      "2021-01-31 18:06:31,094 - INFO - allennlp.common.params - trainer.grad_norm = 5\n",
      "2021-01-31 18:06:31,094 - INFO - allennlp.common.params - trainer.grad_clipping = None\n",
      "2021-01-31 18:06:31,094 - INFO - allennlp.common.params - trainer.distributed = False\n",
      "2021-01-31 18:06:31,094 - INFO - allennlp.common.params - trainer.world_size = 1\n",
      "2021-01-31 18:06:31,094 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1\n",
      "2021-01-31 18:06:31,094 - INFO - allennlp.common.params - trainer.use_amp = False\n",
      "2021-01-31 18:06:31,094 - INFO - allennlp.common.params - trainer.no_grad = None\n",
      "2021-01-31 18:06:31,094 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n",
      "2021-01-31 18:06:31,094 - INFO - allennlp.common.params - trainer.tensorboard_writer = <allennlp.common.lazy.Lazy object at 0x7f1d8c2cde10>\n",
      "2021-01-31 18:06:31,095 - INFO - allennlp.common.params - trainer.moving_average = None\n",
      "2021-01-31 18:06:31,095 - INFO - allennlp.common.params - trainer.batch_callbacks = None\n",
      "2021-01-31 18:06:31,095 - INFO - allennlp.common.params - trainer.epoch_callbacks = None\n",
      "2021-01-31 18:06:31,095 - INFO - allennlp.common.params - trainer.end_callbacks = None\n",
      "2021-01-31 18:06:31,095 - INFO - allennlp.common.params - trainer.trainer_callbacks = None\n",
      "2021-01-31 18:06:44,022 - INFO - allennlp.common.params - trainer.optimizer.type = adamw\n",
      "2021-01-31 18:06:44,022 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.001\n",
      "2021-01-31 18:06:44,022 - INFO - allennlp.common.params - trainer.optimizer.betas = (0.9, 0.999)\n",
      "2021-01-31 18:06:44,022 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08\n",
      "2021-01-31 18:06:44,022 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0\n",
      "2021-01-31 18:06:44,023 - INFO - allennlp.common.params - trainer.optimizer.amsgrad = False\n",
      "2021-01-31 18:06:44,023 - INFO - allennlp.training.optimizers - Done constructing parameter groups.\n",
      "2021-01-31 18:06:44,023 - INFO - allennlp.training.optimizers - Group 0: ['_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias'], {'finetune': True, 'lr': 5e-05, 'weight_decay': 0.01}\n",
      "2021-01-31 18:06:44,025 - INFO - allennlp.training.optimizers - Group 1: ['_coref._mention_pruner._scorer.1._module.weight', '_coref._mention_pruner._scorer.0._module._linear_layers.0.bias', '_coref._antecedent_feedforward._module._linear_layers.0.weight', '_endpoint_span_extractor._span_width_embedding.weight', '_coref._antecedent_feedforward._module._linear_layers.1.weight', '_ner._ner_scorers.genia__ner_labels.0._module._linear_layers.1.weight', '_coref._antecedent_feedforward._module._linear_layers.1.bias', '_coref._antecedent_scorer._module.weight', '_coref._mention_pruner._scorer.0._module._linear_layers.1.bias', '_coref._antecedent_scorer._module.bias', '_ner._ner_scorers.genia__ner_labels.0._module._linear_layers.1.bias', '_coref._mention_pruner._scorer.1._module.bias', '_coref._antecedent_feedforward._module._linear_layers.0.bias', '_coref._f_network._linear_layers.0.weight', '_coref._distance_embedding.weight', '_coref._f_network._linear_layers.0.bias', '_ner._ner_scorers.genia__ner_labels.1._module.weight', '_ner._ner_scorers.genia__ner_labels.0._module._linear_layers.0.bias', '_ner._ner_scorers.genia__ner_labels.1._module.bias', '_coref._mention_pruner._scorer.0._module._linear_layers.0.weight', '_coref._mention_pruner._scorer.0._module._linear_layers.1.weight', '_events._distance_embedding.weight', '_ner._ner_scorers.genia__ner_labels.0._module._linear_layers.0.weight'], {}\n",
      "2021-01-31 18:06:44,025 - INFO - allennlp.training.optimizers - Number of trainable parameters: 115566085\n",
      "2021-01-31 18:06:44,026 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):\n",
      "2021-01-31 18:06:44,028 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):\n",
      "2021-01-31 18:06:44,028 - INFO - allennlp.common.util - _endpoint_span_extractor._span_width_embedding.weight\n",
      "2021-01-31 18:06:44,028 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
      "2021-01-31 18:06:44,028 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
      "2021-01-31 18:06:44,028 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
      "2021-01-31 18:06:44,028 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
      "2021-01-31 18:06:44,028 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
      "2021-01-31 18:06:44,028 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
      "2021-01-31 18:06:44,028 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
      "2021-01-31 18:06:44,028 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
      "2021-01-31 18:06:44,029 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
      "2021-01-31 18:06:44,029 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
      "2021-01-31 18:06:44,029 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
      "2021-01-31 18:06:44,029 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
      "2021-01-31 18:06:44,029 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
      "2021-01-31 18:06:44,029 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,029 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,029 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
      "2021-01-31 18:06:44,029 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
      "2021-01-31 18:06:44,029 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
      "2021-01-31 18:06:44,030 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
      "2021-01-31 18:06:44,030 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,030 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,030 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
      "2021-01-31 18:06:44,030 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
      "2021-01-31 18:06:44,030 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
      "2021-01-31 18:06:44,030 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
      "2021-01-31 18:06:44,030 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
      "2021-01-31 18:06:44,030 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
      "2021-01-31 18:06:44,030 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
      "2021-01-31 18:06:44,030 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
      "2021-01-31 18:06:44,030 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,030 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,030 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
      "2021-01-31 18:06:44,030 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
      "2021-01-31 18:06:44,030 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
      "2021-01-31 18:06:44,030 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
      "2021-01-31 18:06:44,031 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,031 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,031 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
      "2021-01-31 18:06:44,031 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
      "2021-01-31 18:06:44,031 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
      "2021-01-31 18:06:44,031 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
      "2021-01-31 18:06:44,031 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
      "2021-01-31 18:06:44,031 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
      "2021-01-31 18:06:44,031 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
      "2021-01-31 18:06:44,031 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
      "2021-01-31 18:06:44,031 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,031 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,031 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
      "2021-01-31 18:06:44,031 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
      "2021-01-31 18:06:44,031 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
      "2021-01-31 18:06:44,031 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
      "2021-01-31 18:06:44,031 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,031 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,031 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
      "2021-01-31 18:06:44,032 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
      "2021-01-31 18:06:44,032 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
      "2021-01-31 18:06:44,032 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
      "2021-01-31 18:06:44,032 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
      "2021-01-31 18:06:44,032 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
      "2021-01-31 18:06:44,032 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
      "2021-01-31 18:06:44,032 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
      "2021-01-31 18:06:44,032 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,032 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,032 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
      "2021-01-31 18:06:44,032 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
      "2021-01-31 18:06:44,032 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
      "2021-01-31 18:06:44,032 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
      "2021-01-31 18:06:44,032 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,032 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,032 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
      "2021-01-31 18:06:44,032 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
      "2021-01-31 18:06:44,032 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
      "2021-01-31 18:06:44,032 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
      "2021-01-31 18:06:44,032 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
      "2021-01-31 18:06:44,033 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
      "2021-01-31 18:06:44,033 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
      "2021-01-31 18:06:44,033 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
      "2021-01-31 18:06:44,033 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,033 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,033 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
      "2021-01-31 18:06:44,033 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
      "2021-01-31 18:06:44,033 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
      "2021-01-31 18:06:44,033 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
      "2021-01-31 18:06:44,033 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,033 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,033 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
      "2021-01-31 18:06:44,033 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
      "2021-01-31 18:06:44,033 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
      "2021-01-31 18:06:44,033 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
      "2021-01-31 18:06:44,033 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
      "2021-01-31 18:06:44,033 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
      "2021-01-31 18:06:44,033 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
      "2021-01-31 18:06:44,033 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
      "2021-01-31 18:06:44,033 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,034 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,034 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
      "2021-01-31 18:06:44,034 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
      "2021-01-31 18:06:44,034 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
      "2021-01-31 18:06:44,034 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
      "2021-01-31 18:06:44,034 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,034 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,034 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
      "2021-01-31 18:06:44,034 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
      "2021-01-31 18:06:44,034 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
      "2021-01-31 18:06:44,034 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
      "2021-01-31 18:06:44,034 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
      "2021-01-31 18:06:44,034 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
      "2021-01-31 18:06:44,034 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
      "2021-01-31 18:06:44,034 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
      "2021-01-31 18:06:44,034 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,034 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,034 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
      "2021-01-31 18:06:44,034 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
      "2021-01-31 18:06:44,034 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
      "2021-01-31 18:06:44,035 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
      "2021-01-31 18:06:44,035 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,035 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,035 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
      "2021-01-31 18:06:44,035 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
      "2021-01-31 18:06:44,035 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
      "2021-01-31 18:06:44,035 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
      "2021-01-31 18:06:44,035 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
      "2021-01-31 18:06:44,035 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
      "2021-01-31 18:06:44,035 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
      "2021-01-31 18:06:44,035 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
      "2021-01-31 18:06:44,035 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,035 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,035 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
      "2021-01-31 18:06:44,035 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
      "2021-01-31 18:06:44,035 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
      "2021-01-31 18:06:44,035 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
      "2021-01-31 18:06:44,035 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,035 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,035 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
      "2021-01-31 18:06:44,036 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
      "2021-01-31 18:06:44,036 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
      "2021-01-31 18:06:44,036 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
      "2021-01-31 18:06:44,036 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
      "2021-01-31 18:06:44,036 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
      "2021-01-31 18:06:44,036 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
      "2021-01-31 18:06:44,036 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
      "2021-01-31 18:06:44,036 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,036 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,036 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
      "2021-01-31 18:06:44,036 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
      "2021-01-31 18:06:44,036 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
      "2021-01-31 18:06:44,036 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
      "2021-01-31 18:06:44,036 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,036 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,036 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
      "2021-01-31 18:06:44,036 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
      "2021-01-31 18:06:44,036 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
      "2021-01-31 18:06:44,037 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
      "2021-01-31 18:06:44,037 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
      "2021-01-31 18:06:44,037 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
      "2021-01-31 18:06:44,037 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
      "2021-01-31 18:06:44,037 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
      "2021-01-31 18:06:44,037 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,037 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,037 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
      "2021-01-31 18:06:44,037 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
      "2021-01-31 18:06:44,037 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
      "2021-01-31 18:06:44,037 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
      "2021-01-31 18:06:44,037 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,037 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,037 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
      "2021-01-31 18:06:44,037 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
      "2021-01-31 18:06:44,037 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
      "2021-01-31 18:06:44,037 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
      "2021-01-31 18:06:44,038 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
      "2021-01-31 18:06:44,038 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
      "2021-01-31 18:06:44,038 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
      "2021-01-31 18:06:44,038 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
      "2021-01-31 18:06:44,038 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,038 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,038 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
      "2021-01-31 18:06:44,038 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
      "2021-01-31 18:06:44,038 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
      "2021-01-31 18:06:44,038 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
      "2021-01-31 18:06:44,038 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,038 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,038 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
      "2021-01-31 18:06:44,038 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
      "2021-01-31 18:06:44,038 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
      "2021-01-31 18:06:44,038 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
      "2021-01-31 18:06:44,038 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
      "2021-01-31 18:06:44,038 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
      "2021-01-31 18:06:44,038 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
      "2021-01-31 18:06:44,038 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
      "2021-01-31 18:06:44,039 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,039 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,039 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
      "2021-01-31 18:06:44,039 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
      "2021-01-31 18:06:44,039 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
      "2021-01-31 18:06:44,039 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
      "2021-01-31 18:06:44,039 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2021-01-31 18:06:44,039 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2021-01-31 18:06:44,039 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight\n",
      "2021-01-31 18:06:44,039 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias\n",
      "2021-01-31 18:06:44,039 - INFO - allennlp.common.util - _ner._ner_scorers.genia__ner_labels.0._module._linear_layers.0.weight\n",
      "2021-01-31 18:06:44,039 - INFO - allennlp.common.util - _ner._ner_scorers.genia__ner_labels.0._module._linear_layers.0.bias\n",
      "2021-01-31 18:06:44,039 - INFO - allennlp.common.util - _ner._ner_scorers.genia__ner_labels.0._module._linear_layers.1.weight\n",
      "2021-01-31 18:06:44,039 - INFO - allennlp.common.util - _ner._ner_scorers.genia__ner_labels.0._module._linear_layers.1.bias\n",
      "2021-01-31 18:06:44,039 - INFO - allennlp.common.util - _ner._ner_scorers.genia__ner_labels.1._module.weight\n",
      "2021-01-31 18:06:44,039 - INFO - allennlp.common.util - _ner._ner_scorers.genia__ner_labels.1._module.bias\n",
      "2021-01-31 18:06:44,039 - INFO - allennlp.common.util - _coref._distance_embedding.weight\n",
      "2021-01-31 18:06:44,039 - INFO - allennlp.common.util - _coref._antecedent_feedforward._module._linear_layers.0.weight\n",
      "2021-01-31 18:06:44,039 - INFO - allennlp.common.util - _coref._antecedent_feedforward._module._linear_layers.0.bias\n",
      "2021-01-31 18:06:44,040 - INFO - allennlp.common.util - _coref._antecedent_feedforward._module._linear_layers.1.weight\n",
      "2021-01-31 18:06:44,040 - INFO - allennlp.common.util - _coref._antecedent_feedforward._module._linear_layers.1.bias\n",
      "2021-01-31 18:06:44,040 - INFO - allennlp.common.util - _coref._mention_pruner._scorer.0._module._linear_layers.0.weight\n",
      "2021-01-31 18:06:44,040 - INFO - allennlp.common.util - _coref._mention_pruner._scorer.0._module._linear_layers.0.bias\n",
      "2021-01-31 18:06:44,040 - INFO - allennlp.common.util - _coref._mention_pruner._scorer.0._module._linear_layers.1.weight\n",
      "2021-01-31 18:06:44,040 - INFO - allennlp.common.util - _coref._mention_pruner._scorer.0._module._linear_layers.1.bias\n",
      "2021-01-31 18:06:44,040 - INFO - allennlp.common.util - _coref._mention_pruner._scorer.1._module.weight\n",
      "2021-01-31 18:06:44,040 - INFO - allennlp.common.util - _coref._mention_pruner._scorer.1._module.bias\n",
      "2021-01-31 18:06:44,040 - INFO - allennlp.common.util - _coref._antecedent_scorer._module.weight\n",
      "2021-01-31 18:06:44,040 - INFO - allennlp.common.util - _coref._antecedent_scorer._module.bias\n",
      "2021-01-31 18:06:44,040 - INFO - allennlp.common.util - _coref._f_network._linear_layers.0.weight\n",
      "2021-01-31 18:06:44,040 - INFO - allennlp.common.util - _coref._f_network._linear_layers.0.bias\n",
      "2021-01-31 18:06:44,040 - INFO - allennlp.common.util - _events._distance_embedding.weight\n",
      "2021-01-31 18:06:44,040 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = slanted_triangular\n",
      "2021-01-31 18:06:44,041 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.cut_frac = 0.1\n",
      "2021-01-31 18:06:44,041 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.ratio = 32\n",
      "2021-01-31 18:06:44,041 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.last_epoch = -1\n",
      "2021-01-31 18:06:44,041 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.gradual_unfreezing = False\n",
      "2021-01-31 18:06:44,041 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.discriminative_fine_tuning = False\n",
      "2021-01-31 18:06:44,041 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.decay_factor = 0.38\n",
      "2021-01-31 18:06:44,041 - INFO - allennlp.common.params - trainer.checkpointer.type = default\n",
      "2021-01-31 18:06:44,041 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None\n",
      "2021-01-31 18:06:44,041 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 3\n",
      "2021-01-31 18:06:44,041 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None\n",
      "2021-01-31 18:06:44,041 - INFO - allennlp.common.params - summary_interval = 100\n",
      "2021-01-31 18:06:44,042 - INFO - allennlp.common.params - histogram_interval = None\n",
      "2021-01-31 18:06:44,042 - INFO - allennlp.common.params - batch_size_interval = None\n",
      "2021-01-31 18:06:44,042 - INFO - allennlp.common.params - should_log_parameter_statistics = True\n",
      "2021-01-31 18:06:44,042 - INFO - allennlp.common.params - should_log_learning_rate = False\n",
      "2021-01-31 18:06:44,042 - INFO - allennlp.common.params - get_batch_num_total = None\n",
      "2021-01-31 18:06:44,044 - WARNING - allennlp.training.trainer - You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n",
      "2021-01-31 18:06:44,044 - INFO - allennlp.training.trainer - Beginning training.\n",
      "2021-01-31 18:06:44,044 - INFO - allennlp.training.trainer - Epoch 0/2\n",
      "2021-01-31 18:06:44,044 - INFO - allennlp.training.trainer - Worker 0 memory usage: 3.6G\n",
      "2021-01-31 18:06:44,044 - INFO - allennlp.training.trainer - GPU 0 memory usage: 442M\n",
      "2021-01-31 18:06:44,045 - INFO - allennlp.training.trainer - Training\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]2021-01-31 18:06:45,078 - WARNING - allennlp.training.util - Metrics with names beginning with \"_\" will not be logged to the tqdm progress bar.\n",
      "MEAN__ner_precision: 0.0181, MEAN__ner_recall: 0.1164, MEAN__ner_f1: 0.0313, batch_loss: 91.6814, loss: 975.4569 ||: 100%|##########| 100/100 [00:44<00:00,  2.27it/s]  \n",
      "2021-01-31 18:07:29,190 - INFO - allennlp.training.trainer - Validating\n",
      "MEAN__ner_precision: 0.6917, MEAN__ner_recall: 0.3887, MEAN__ner_f1: 0.4977, batch_loss: 81.1427, loss: 83.7042 ||: 100%|##########| 100/100 [00:17<00:00,  5.61it/s] \n",
      "2021-01-31 18:07:47,027 - INFO - allennlp.training.tensorboard_writer -                                 Training |  Validation\n",
      "2021-01-31 18:07:47,028 - INFO - allennlp.training.tensorboard_writer - MEAN__ner_f1                |     0.031  |     0.498\n",
      "2021-01-31 18:07:47,029 - INFO - allennlp.training.tensorboard_writer - MEAN__ner_precision         |     0.018  |     0.692\n",
      "2021-01-31 18:07:47,030 - INFO - allennlp.training.tensorboard_writer - MEAN__ner_recall            |     0.116  |     0.389\n",
      "2021-01-31 18:07:47,030 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_class_f1         |     0.000  |     0.000\n",
      "2021-01-31 18:07:47,031 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_class_precision  |     0.000  |     0.000\n",
      "2021-01-31 18:07:47,031 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_class_recall     |     0.000  |     0.000\n",
      "2021-01-31 18:07:47,032 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_id_f1            |     0.000  |     0.000\n",
      "2021-01-31 18:07:47,032 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_id_precision     |     0.000  |     0.000\n",
      "2021-01-31 18:07:47,033 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_id_recall        |     0.000  |     0.000\n",
      "2021-01-31 18:07:47,034 - INFO - allennlp.training.tensorboard_writer - _MEAN__relation_f1          |     0.000  |     0.000\n",
      "2021-01-31 18:07:47,035 - INFO - allennlp.training.tensorboard_writer - _MEAN__relation_precision   |     0.000  |     0.000\n",
      "2021-01-31 18:07:47,035 - INFO - allennlp.training.tensorboard_writer - _MEAN__relation_recall      |     0.000  |     0.000\n",
      "2021-01-31 18:07:47,035 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_class_f1        |     0.000  |     0.000\n",
      "2021-01-31 18:07:47,036 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_class_precision |     0.000  |     0.000\n",
      "2021-01-31 18:07:47,037 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_class_recall    |     0.000  |     0.000\n",
      "2021-01-31 18:07:47,037 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_id_f1           |     0.000  |     0.000\n",
      "2021-01-31 18:07:47,038 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_id_precision    |     0.000  |     0.000\n",
      "2021-01-31 18:07:47,038 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_id_recall       |     0.000  |     0.000\n",
      "2021-01-31 18:07:47,039 - INFO - allennlp.training.tensorboard_writer - _coref_f1                   |     0.002  |     0.000\n",
      "2021-01-31 18:07:47,040 - INFO - allennlp.training.tensorboard_writer - _coref_mention_recall       |     0.132  |     0.400\n",
      "2021-01-31 18:07:47,041 - INFO - allennlp.training.tensorboard_writer - _coref_precision            |     0.016  |     0.000\n",
      "2021-01-31 18:07:47,041 - INFO - allennlp.training.tensorboard_writer - _coref_recall               |     0.002  |     0.000\n",
      "2021-01-31 18:07:47,042 - INFO - allennlp.training.tensorboard_writer - _genia__ner_f1              |     0.031  |     0.498\n",
      "2021-01-31 18:07:47,042 - INFO - allennlp.training.tensorboard_writer - _genia__ner_precision       |     0.018  |     0.692\n",
      "2021-01-31 18:07:47,043 - INFO - allennlp.training.tensorboard_writer - _genia__ner_recall          |     0.116  |     0.389\n",
      "2021-01-31 18:07:47,043 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB             |   441.941  |       N/A\n",
      "2021-01-31 18:07:47,044 - INFO - allennlp.training.tensorboard_writer - loss                        |   975.457  |    83.704\n",
      "2021-01-31 18:07:47,044 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB          |  3665.398  |       N/A\n",
      "2021-01-31 18:07:48,619 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'models/genia2/best.th'.\n",
      "2021-01-31 18:07:49,400 - INFO - allennlp.training.trainer - Epoch duration: 0:01:05.355704\n",
      "2021-01-31 18:07:49,400 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:02:10\n",
      "2021-01-31 18:07:49,400 - INFO - allennlp.training.trainer - Epoch 1/2\n",
      "2021-01-31 18:07:49,400 - INFO - allennlp.training.trainer - Worker 0 memory usage: 3.6G\n",
      "2021-01-31 18:07:49,400 - INFO - allennlp.training.trainer - GPU 0 memory usage: 4.4G\n",
      "2021-01-31 18:07:49,402 - INFO - allennlp.training.trainer - Training\n",
      "MEAN__ner_precision: 0.6640, MEAN__ner_recall: 0.4872, MEAN__ner_f1: 0.5620, batch_loss: 77.4057, loss: 81.7172 ||: 100%|##########| 100/100 [00:40<00:00,  2.47it/s] \n",
      "2021-01-31 18:08:30,647 - INFO - allennlp.training.trainer - Validating\n",
      "MEAN__ner_precision: 0.6540, MEAN__ner_recall: 0.6395, MEAN__ner_f1: 0.6466, batch_loss: 94.0688, loss: 71.0039 ||: 100%|##########| 100/100 [00:15<00:00,  6.37it/s]\n",
      "2021-01-31 18:08:46,341 - INFO - allennlp.training.tensorboard_writer -                                 Training |  Validation\n",
      "2021-01-31 18:08:46,341 - INFO - allennlp.training.tensorboard_writer - MEAN__ner_f1                |     0.562  |     0.647\n",
      "2021-01-31 18:08:46,342 - INFO - allennlp.training.tensorboard_writer - MEAN__ner_precision         |     0.664  |     0.654\n",
      "2021-01-31 18:08:46,342 - INFO - allennlp.training.tensorboard_writer - MEAN__ner_recall            |     0.487  |     0.639\n",
      "2021-01-31 18:08:46,343 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_class_f1         |     0.000  |     0.000\n",
      "2021-01-31 18:08:46,343 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_class_precision  |     0.000  |     0.000\n",
      "2021-01-31 18:08:46,344 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_class_recall     |     0.000  |     0.000\n",
      "2021-01-31 18:08:46,344 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_id_f1            |     0.000  |     0.000\n",
      "2021-01-31 18:08:46,345 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_id_precision     |     0.000  |     0.000\n",
      "2021-01-31 18:08:46,345 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_id_recall        |     0.000  |     0.000\n",
      "2021-01-31 18:08:46,346 - INFO - allennlp.training.tensorboard_writer - _MEAN__relation_f1          |     0.000  |     0.000\n",
      "2021-01-31 18:08:46,347 - INFO - allennlp.training.tensorboard_writer - _MEAN__relation_precision   |     0.000  |     0.000\n",
      "2021-01-31 18:08:46,348 - INFO - allennlp.training.tensorboard_writer - _MEAN__relation_recall      |     0.000  |     0.000\n",
      "2021-01-31 18:08:46,349 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_class_f1        |     0.000  |     0.000\n",
      "2021-01-31 18:08:46,353 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_class_precision |     0.000  |     0.000\n",
      "2021-01-31 18:08:46,353 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_class_recall    |     0.000  |     0.000\n",
      "2021-01-31 18:08:46,354 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_id_f1           |     0.000  |     0.000\n",
      "2021-01-31 18:08:46,354 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_id_precision    |     0.000  |     0.000\n",
      "2021-01-31 18:08:46,355 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_id_recall       |     0.000  |     0.000\n",
      "2021-01-31 18:08:46,355 - INFO - allennlp.training.tensorboard_writer - _coref_f1                   |     0.006  |     0.008\n",
      "2021-01-31 18:08:46,355 - INFO - allennlp.training.tensorboard_writer - _coref_mention_recall       |     0.212  |     0.445\n",
      "2021-01-31 18:08:46,355 - INFO - allennlp.training.tensorboard_writer - _coref_precision            |     0.367  |     0.861\n",
      "2021-01-31 18:08:46,356 - INFO - allennlp.training.tensorboard_writer - _coref_recall               |     0.003  |     0.004\n",
      "2021-01-31 18:08:46,356 - INFO - allennlp.training.tensorboard_writer - _genia__ner_f1              |     0.562  |     0.647\n",
      "2021-01-31 18:08:46,356 - INFO - allennlp.training.tensorboard_writer - _genia__ner_precision       |     0.664  |     0.654\n",
      "2021-01-31 18:08:46,358 - INFO - allennlp.training.tensorboard_writer - _genia__ner_recall          |     0.487  |     0.639\n",
      "2021-01-31 18:08:46,359 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB             |  4534.340  |       N/A\n",
      "2021-01-31 18:08:46,359 - INFO - allennlp.training.tensorboard_writer - loss                        |    81.717  |    71.004\n",
      "2021-01-31 18:08:46,360 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB          |  3665.398  |       N/A\n",
      "2021-01-31 18:08:48,197 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'models/genia2/best.th'.\n",
      "2021-01-31 18:08:55,688 - INFO - allennlp.training.trainer - Epoch duration: 0:01:06.287983\n",
      "2021-01-31 18:08:55,688 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:01:05\n",
      "2021-01-31 18:08:55,688 - INFO - allennlp.training.trainer - Epoch 2/2\n",
      "2021-01-31 18:08:55,689 - INFO - allennlp.training.trainer - Worker 0 memory usage: 3.6G\n",
      "2021-01-31 18:08:55,689 - INFO - allennlp.training.trainer - GPU 0 memory usage: 4.4G\n",
      "2021-01-31 18:08:55,691 - INFO - allennlp.training.trainer - Training\n",
      "MEAN__ner_precision: 0.7443, MEAN__ner_recall: 0.6758, MEAN__ner_f1: 0.7084, batch_loss: 27.2123, loss: 56.9333 ||: 100%|##########| 100/100 [00:41<00:00,  2.42it/s]\n",
      "2021-01-31 18:09:37,940 - INFO - allennlp.training.trainer - Validating\n",
      "MEAN__ner_precision: 0.6320, MEAN__ner_recall: 0.7265, MEAN__ner_f1: 0.6759, batch_loss: 81.1480, loss: 72.7855 ||: 100%|##########| 100/100 [00:15<00:00,  6.33it/s]\n",
      "2021-01-31 18:09:53,739 - INFO - allennlp.training.tensorboard_writer -                                 Training |  Validation\n",
      "2021-01-31 18:09:53,740 - INFO - allennlp.training.tensorboard_writer - MEAN__ner_f1                |     0.708  |     0.676\n",
      "2021-01-31 18:09:53,741 - INFO - allennlp.training.tensorboard_writer - MEAN__ner_precision         |     0.744  |     0.632\n",
      "2021-01-31 18:09:53,741 - INFO - allennlp.training.tensorboard_writer - MEAN__ner_recall            |     0.676  |     0.727\n",
      "2021-01-31 18:09:53,741 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_class_f1         |     0.000  |     0.000\n",
      "2021-01-31 18:09:53,741 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_class_precision  |     0.000  |     0.000\n",
      "2021-01-31 18:09:53,741 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_class_recall     |     0.000  |     0.000\n",
      "2021-01-31 18:09:53,742 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_id_f1            |     0.000  |     0.000\n",
      "2021-01-31 18:09:53,742 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_id_precision     |     0.000  |     0.000\n",
      "2021-01-31 18:09:53,742 - INFO - allennlp.training.tensorboard_writer - _MEAN__arg_id_recall        |     0.000  |     0.000\n",
      "2021-01-31 18:09:53,743 - INFO - allennlp.training.tensorboard_writer - _MEAN__relation_f1          |     0.000  |     0.000\n",
      "2021-01-31 18:09:53,743 - INFO - allennlp.training.tensorboard_writer - _MEAN__relation_precision   |     0.000  |     0.000\n",
      "2021-01-31 18:09:53,744 - INFO - allennlp.training.tensorboard_writer - _MEAN__relation_recall      |     0.000  |     0.000\n",
      "2021-01-31 18:09:53,746 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_class_f1        |     0.000  |     0.000\n",
      "2021-01-31 18:09:53,746 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_class_precision |     0.000  |     0.000\n",
      "2021-01-31 18:09:53,747 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_class_recall    |     0.000  |     0.000\n",
      "2021-01-31 18:09:53,747 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_id_f1           |     0.000  |     0.000\n",
      "2021-01-31 18:09:53,748 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_id_precision    |     0.000  |     0.000\n",
      "2021-01-31 18:09:53,748 - INFO - allennlp.training.tensorboard_writer - _MEAN__trig_id_recall       |     0.000  |     0.000\n",
      "2021-01-31 18:09:53,749 - INFO - allennlp.training.tensorboard_writer - _coref_f1                   |     0.032  |     0.040\n",
      "2021-01-31 18:09:53,749 - INFO - allennlp.training.tensorboard_writer - _coref_mention_recall       |     0.212  |     0.494\n",
      "2021-01-31 18:09:53,750 - INFO - allennlp.training.tensorboard_writer - _coref_precision            |     0.600  |     0.674\n",
      "2021-01-31 18:09:53,751 - INFO - allennlp.training.tensorboard_writer - _coref_recall               |     0.016  |     0.021\n",
      "2021-01-31 18:09:53,751 - INFO - allennlp.training.tensorboard_writer - _genia__ner_f1              |     0.708  |     0.676\n",
      "2021-01-31 18:09:53,752 - INFO - allennlp.training.tensorboard_writer - _genia__ner_precision       |     0.744  |     0.632\n",
      "2021-01-31 18:09:53,752 - INFO - allennlp.training.tensorboard_writer - _genia__ner_recall          |     0.676  |     0.727\n",
      "2021-01-31 18:09:53,752 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB             |  4534.649  |       N/A\n",
      "2021-01-31 18:09:53,753 - INFO - allennlp.training.tensorboard_writer - loss                        |    56.933  |    72.785\n",
      "2021-01-31 18:09:53,753 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB          |  3665.398  |       N/A\n",
      "2021-01-31 18:09:55,489 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'models/genia2/best.th'.\n",
      "2021-01-31 18:10:02,982 - INFO - allennlp.training.trainer - Epoch duration: 0:01:07.293421\n",
      "2021-01-31 18:10:02,982 - INFO - allennlp.training.checkpointer - loading best weights\n",
      "2021-01-31 18:10:03,324 - INFO - allennlp.commands.train - To evaluate on the test set after training, pass the 'evaluate_on_test' flag, or use the 'allennlp evaluate' command.\n",
      "2021-01-31 18:10:03,326 - INFO - allennlp.common.util - Metrics: {\n",
      "  \"best_epoch\": 2,\n",
      "  \"peak_worker_0_memory_MB\": 3665.3984375,\n",
      "  \"peak_gpu_0_memory_MB\": 4534.64892578125,\n",
      "  \"training_duration\": \"0:03:09.709847\",\n",
      "  \"training_start_epoch\": 0,\n",
      "  \"training_epochs\": 2,\n",
      "  \"epoch\": 2,\n",
      "  \"training__coref_precision\": 0.5995890430819509,\n",
      "  \"training__coref_recall\": 0.01633775286793785,\n",
      "  \"training__coref_f1\": 0.031716626382338735,\n",
      "  \"training__coref_mention_recall\": 0.2118942731277533,\n",
      "  \"training__genia__ner_precision\": 0.7442953020134229,\n",
      "  \"training__genia__ner_recall\": 0.6758074344911639,\n",
      "  \"training__genia__ner_f1\": 0.708399872245289,\n",
      "  \"training_MEAN__ner_precision\": 0.7442953020134229,\n",
      "  \"training_MEAN__ner_recall\": 0.6758074344911639,\n",
      "  \"training_MEAN__ner_f1\": 0.708399872245289,\n",
      "  \"training__MEAN__relation_precision\": 0,\n",
      "  \"training__MEAN__relation_recall\": 0,\n",
      "  \"training__MEAN__relation_f1\": 0,\n",
      "  \"training__MEAN__trig_id_precision\": 0,\n",
      "  \"training__MEAN__trig_id_recall\": 0,\n",
      "  \"training__MEAN__trig_id_f1\": 0,\n",
      "  \"training__MEAN__trig_class_precision\": 0,\n",
      "  \"training__MEAN__trig_class_recall\": 0,\n",
      "  \"training__MEAN__trig_class_f1\": 0,\n",
      "  \"training__MEAN__arg_id_precision\": 0,\n",
      "  \"training__MEAN__arg_id_recall\": 0,\n",
      "  \"training__MEAN__arg_id_f1\": 0,\n",
      "  \"training__MEAN__arg_class_precision\": 0,\n",
      "  \"training__MEAN__arg_class_recall\": 0,\n",
      "  \"training__MEAN__arg_class_f1\": 0,\n",
      "  \"training_loss\": 56.933292561769484,\n",
      "  \"training_worker_0_memory_MB\": 3665.3984375,\n",
      "  \"training_gpu_0_memory_MB\": 4534.64892578125,\n",
      "  \"validation__coref_precision\": 0.6735009089114156,\n",
      "  \"validation__coref_recall\": 0.020562446735605523,\n",
      "  \"validation__coref_f1\": 0.03986480882254375,\n",
      "  \"validation__coref_mention_recall\": 0.49388077378602446,\n",
      "  \"validation__genia__ner_precision\": 0.6319526627218935,\n",
      "  \"validation__genia__ner_recall\": 0.726530612244898,\n",
      "  \"validation__genia__ner_f1\": 0.6759493670886076,\n",
      "  \"validation_MEAN__ner_precision\": 0.6319526627218935,\n",
      "  \"validation_MEAN__ner_recall\": 0.726530612244898,\n",
      "  \"validation_MEAN__ner_f1\": 0.6759493670886076,\n",
      "  \"validation__MEAN__relation_precision\": 0,\n",
      "  \"validation__MEAN__relation_recall\": 0,\n",
      "  \"validation__MEAN__relation_f1\": 0,\n",
      "  \"validation__MEAN__trig_id_precision\": 0,\n",
      "  \"validation__MEAN__trig_id_recall\": 0,\n",
      "  \"validation__MEAN__trig_id_f1\": 0,\n",
      "  \"validation__MEAN__trig_class_precision\": 0,\n",
      "  \"validation__MEAN__trig_class_recall\": 0,\n",
      "  \"validation__MEAN__trig_class_f1\": 0,\n",
      "  \"validation__MEAN__arg_id_precision\": 0,\n",
      "  \"validation__MEAN__arg_id_recall\": 0,\n",
      "  \"validation__MEAN__arg_id_f1\": 0,\n",
      "  \"validation__MEAN__arg_class_precision\": 0,\n",
      "  \"validation__MEAN__arg_class_recall\": 0,\n",
      "  \"validation__MEAN__arg_class_f1\": 0,\n",
      "  \"validation_loss\": 72.78547218322754,\n",
      "  \"best_validation__coref_precision\": 0.6735009089114156,\n",
      "  \"best_validation__coref_recall\": 0.020562446735605523,\n",
      "  \"best_validation__coref_f1\": 0.03986480882254375,\n",
      "  \"best_validation__coref_mention_recall\": 0.49388077378602446,\n",
      "  \"best_validation__genia__ner_precision\": 0.6319526627218935,\n",
      "  \"best_validation__genia__ner_recall\": 0.726530612244898,\n",
      "  \"best_validation__genia__ner_f1\": 0.6759493670886076,\n",
      "  \"best_validation_MEAN__ner_precision\": 0.6319526627218935,\n",
      "  \"best_validation_MEAN__ner_recall\": 0.726530612244898,\n",
      "  \"best_validation_MEAN__ner_f1\": 0.6759493670886076,\n",
      "  \"best_validation__MEAN__relation_precision\": 0,\n",
      "  \"best_validation__MEAN__relation_recall\": 0,\n",
      "  \"best_validation__MEAN__relation_f1\": 0,\n",
      "  \"best_validation__MEAN__trig_id_precision\": 0,\n",
      "  \"best_validation__MEAN__trig_id_recall\": 0,\n",
      "  \"best_validation__MEAN__trig_id_f1\": 0,\n",
      "  \"best_validation__MEAN__trig_class_precision\": 0,\n",
      "  \"best_validation__MEAN__trig_class_recall\": 0,\n",
      "  \"best_validation__MEAN__trig_class_f1\": 0,\n",
      "  \"best_validation__MEAN__arg_id_precision\": 0,\n",
      "  \"best_validation__MEAN__arg_id_recall\": 0,\n",
      "  \"best_validation__MEAN__arg_id_f1\": 0,\n",
      "  \"best_validation__MEAN__arg_class_precision\": 0,\n",
      "  \"best_validation__MEAN__arg_class_recall\": 0,\n",
      "  \"best_validation__MEAN__arg_class_f1\": 0,\n",
      "  \"best_validation_loss\": 72.78547218322754\n",
      "}\n",
      "2021-01-31 18:10:03,356 - INFO - allennlp.models.archival - archiving weights and vocabulary to models/genia2/model.tar.gz\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!allennlp train \"training_config/genia2.jsonnet\" \\\n",
    "    --serialization-dir \"models/genia2\" \\\n",
    "    --include-package dygie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-crime",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
